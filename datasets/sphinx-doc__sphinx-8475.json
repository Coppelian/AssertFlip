{
  "instance_id": "sphinx-doc__sphinx-8475",
  "problem_statement": "Extend linkchecker GET fallback logic to handle Too Many Redirects\nSubject: linkcheck - fallback to GET requests when HEAD requests returns Too Many Redirects\r\n\r\n### Feature or Bugfix\r\n\r\n- Bugfix\r\n\r\n### Purpose\r\n\r\nSome websites will enter infinite redirect loops with HEAD requests. In this case, the GET fallback is ignored as the exception is of type `TooManyRedirects` and the link is reported as broken.\r\nThis extends the except clause to retry with a GET request for such scenarios.\r\n\r\n### Detail\r\n\r\nClassifying this as a bug fix as URLs like https://idr.openmicroscopy.org/webclient/?show=well-119093 used to pass the linkchecking prior to Sphinx 3.2.0 but are now failing as HEAD requests have been enforced (#7936).\r\n\r\n/cc @mtbc @jburel @manics @joshmoore\r\n\n",
  "localized_code": "[start of sphinx/builders/linkcheck.py]\n1: \"\"\"\n2:     sphinx.builders.linkcheck\n3:     ~~~~~~~~~~~~~~~~~~~~~~~~~\n4: \n5:     The CheckExternalLinksBuilder class.\n6: \n7:     :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.\n8:     :license: BSD, see LICENSE for details.\n9: \"\"\"\n10: \n11: import json\n12: import queue\n13: import re\n14: import socket\n15: import threading\n16: from html.parser import HTMLParser\n17: from os import path\n18: from typing import Any, Dict, List, Set, Tuple\n19: from urllib.parse import unquote, urlparse\n20: \n21: from docutils import nodes\n22: from docutils.nodes import Node\n23: from requests.exceptions import HTTPError\n24: \n25: from sphinx.application import Sphinx\n26: from sphinx.builders import Builder\n27: from sphinx.locale import __\n28: from sphinx.util import encode_uri, logging, requests\n29: from sphinx.util.console import darkgray, darkgreen, purple, red, turquoise  # type: ignore\n30: from sphinx.util.nodes import get_node_line\n31: \n32: logger = logging.getLogger(__name__)\n33: \n34: uri_re = re.compile('([a-z]+:)?//')  # matches to foo:// and // (a protocol relative URL)\n35: \n36: \n37: DEFAULT_REQUEST_HEADERS = {\n38:     'Accept': 'text/html,application/xhtml+xml;q=0.9,*/*;q=0.8',\n39: }\n40: \n41: \n42: class AnchorCheckParser(HTMLParser):\n43:     \"\"\"Specialized HTML parser that looks for a specific anchor.\"\"\"\n44: \n45:     def __init__(self, search_anchor: str) -> None:\n46:         super().__init__()\n47: \n48:         self.search_anchor = search_anchor\n49:         self.found = False\n50: \n51:     def handle_starttag(self, tag: Any, attrs: Any) -> None:\n52:         for key, value in attrs:\n53:             if key in ('id', 'name') and value == self.search_anchor:\n54:                 self.found = True\n55:                 break\n56: \n57: \n58: def check_anchor(response: requests.requests.Response, anchor: str) -> bool:\nCode replaced for brevity.\n73: \n74: \n75: \n76: class CheckExternalLinksBuilder(Builder):\n77:     \"\"\"\n78:     Checks for broken external links.\n79:     \"\"\"\n80:     name = 'linkcheck'\n81:     epilog = __('Look for any errors in the above output or in '\n82:                 '%(outdir)s/output.txt')\n83: \n84:     def init(self) -> None:\n85:         self.to_ignore = [re.compile(x) for x in self.app.config.linkcheck_ignore]\n86:         self.anchors_ignore = [re.compile(x)\n87:                                for x in self.app.config.linkcheck_anchors_ignore]\n88:         self.auth = [(re.compile(pattern), auth_info) for pattern, auth_info\n89:                      in self.app.config.linkcheck_auth]\n90:         self.good = set()       # type: Set[str]\n91:         self.broken = {}        # type: Dict[str, str]\n92:         self.redirected = {}    # type: Dict[str, Tuple[str, int]]\n93:         # set a timeout for non-responding servers\n94:         socket.setdefaulttimeout(5.0)\n95:         # create output file\n96:         open(path.join(self.outdir, 'output.txt'), 'w').close()\n97:         # create JSON output file\n98:         open(path.join(self.outdir, 'output.json'), 'w').close()\n99: \n100:         # create queues and worker threads\n101:         self.wqueue = queue.Queue()  # type: queue.Queue\n102:         self.rqueue = queue.Queue()  # type: queue.Queue\n103:         self.workers = []  # type: List[threading.Thread]\n104:         for i in range(self.app.config.linkcheck_workers):\n105:             thread = threading.Thread(target=self.check_thread, daemon=True)\n106:             thread.start()\n107:             self.workers.append(thread)\n108: \n109:     def check_thread(self) -> None:\n110:         kwargs = {}\n111:         if self.app.config.linkcheck_timeout:\n112:             kwargs['timeout'] = self.app.config.linkcheck_timeout\n113: \n114:         def get_request_headers() -> Dict:\n115:             url = urlparse(uri)\n116:             candidates = [\"%s://%s\" % (url.scheme, url.netloc),\n117:                           \"%s://%s/\" % (url.scheme, url.netloc),\n118:                           uri,\n119:                           \"*\"]\n120: \n121:             for u in candidates:\n122:                 if u in self.config.linkcheck_request_headers:\n123:                     headers = dict(DEFAULT_REQUEST_HEADERS)\n124:                     headers.update(self.config.linkcheck_request_headers[u])\n125:                     return headers\n126: \n127:             return {}\n128: \n129:         def check_uri() -> Tuple[str, str, int]:\n130:             # split off anchor\n131:             if '#' in uri:\n132:                 req_url, anchor = uri.split('#', 1)\n133:                 for rex in self.anchors_ignore:\n134:                     if rex.match(anchor):\n135:                         anchor = None\n136:                         break\n137:             else:\n138:                 req_url = uri\n139:                 anchor = None\n140: \n141:             # handle non-ASCII URIs\n142:             try:\n143:                 req_url.encode('ascii')\n144:             except UnicodeError:\n145:                 req_url = encode_uri(req_url)\n146: \n147:             # Get auth info, if any\n148:             for pattern, auth_info in self.auth:\n149:                 if pattern.match(uri):\n150:                     break\n151:             else:\n152:                 auth_info = None\n153: \n154:             # update request headers for the URL\n155:             kwargs['headers'] = get_request_headers()\n156: \n157:             try:\n158:                 if anchor and self.app.config.linkcheck_anchors:\n159:                     # Read the whole document and see if #anchor exists\n160:                     response = requests.get(req_url, stream=True, config=self.app.config,\n161:                                             auth=auth_info, **kwargs)\n162:                     response.raise_for_status()\n163:                     found = check_anchor(response, unquote(anchor))\n164: \n165:                     if not found:\n166:                         raise Exception(__(\"Anchor '%s' not found\") % anchor)\n167:                 else:\n168:                     try:\n169:                         # try a HEAD request first, which should be easier on\n170:                         # the server and the network\n171:                         response = requests.head(req_url, allow_redirects=True,\n172:                                                  config=self.app.config, auth=auth_info,\n173:                                                  **kwargs)\n174:                         response.raise_for_status()\n175:                     except HTTPError:\n176:                         # retry with GET request if that fails, some servers\n177:                         # don't like HEAD requests.\n178:                         response = requests.get(req_url, stream=True, config=self.app.config,\n179:                                                 auth=auth_info, **kwargs)\n180:                         response.raise_for_status()\n181:             except HTTPError as err:\n182:                 if err.response.status_code == 401:\n183:                     # We'll take \"Unauthorized\" as working.\n184:                     return 'working', ' - unauthorized', 0\n185:                 elif err.response.status_code == 503:\n186:                     # We'll take \"Service Unavailable\" as ignored.\n187:                     return 'ignored', str(err), 0\n188:                 else:\n189:                     return 'broken', str(err), 0\n... Code Truncated ...\n\n",
  "line_level_localization": [
    {
      "filename": "/sphinx/builders/linkcheck.py",
      "suspect_lines": [
        23,
        175
      ]
    }
  ]
}