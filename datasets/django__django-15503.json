{
  "instance_id": "django__django-15503",
  "problem_statement": "has_key, has_keys, and has_any_keys JSONField() lookups don't handle numeric keys on SQLite, MySQL, and Oracle.\nDescription\n\t \n\t\t(last modified by TheTerrasque)\n\t \nProblem\nWhen using models.​JSONField() ​has_key lookup with numerical keys on SQLite database it fails to find the keys.\nVersions:\nDjango: 4.0.3\nPython: 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)] on win32\nsqlite3.version: '2.6.0'\nsqlite3.sqlite_version: '3.35.5'\nExample:\nDatabase\nDATABASES = {\n\t'default': {\n\t\t'ENGINE': 'django.db.backends.sqlite3',\n\t\t'NAME': 'db.sqlite3',\n\t}\n}\nModel\nclass JsonFieldHasKeyTest(models.Model):\n\tdata = models.JSONField()\nTest\nfrom django.test import TestCase\nfrom .models import JsonFieldHasKeyTest\nclass JsonFieldHasKeyTestCase(TestCase):\n\tdef setUp(self) -> None:\n\t\ttest = JsonFieldHasKeyTest(data={'foo': 'bar'})\n\t\ttest2 = JsonFieldHasKeyTest(data={'1111': 'bar'})\n\t\ttest.save()\n\t\ttest2.save()\n\tdef test_json_field_has_key(self):\n\t\tc1 = JsonFieldHasKeyTest.objects.filter(data__has_key='foo').count()\n\t\tc2 = JsonFieldHasKeyTest.objects.filter(data__has_key='1111').count()\n\t\tself.assertEqual(c1, 1, \"Should have found 1 entry with key 'foo'\")\n\t\tself.assertEqual(c2, 1, \"Should have found 1 entry with key '1111'\")\nResult\nFAIL: test_json_field_has_key (markers.tests.JsonFieldHasKeyTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n File \"H:\\Files\\Projects\\Electaco\\Webservice\\elecserve\\markers\\tests.py\", line 16, in test_json_field_has_key\t \n\tself.assertEqual(c2, 1, \"Should have found 1 entry with key '1111'\")\nAssertionError: 0 != 1 : Should have found 1 entry with key '1111'\nAdditional info\nThis has been tested on SQLite and Postgresql backend, it works on postgresql but fails on sqlite.\n",
  "localized_code": "[start of django/db/models/fields/json.py]\n1: import json\n2: \n3: from django import forms\n4: from django.core import checks, exceptions\n5: from django.db import NotSupportedError, connections, router\n6: from django.db.models import lookups\n7: from django.db.models.lookups import PostgresOperatorLookup, Transform\n8: from django.utils.translation import gettext_lazy as _\n9: \n10: from . import Field\n11: from .mixins import CheckFieldDefaultMixin\n12: \n13: __all__ = [\"JSONField\"]\n14: \n15: \n16: class JSONField(CheckFieldDefaultMixin, Field):\n17:     empty_strings_allowed = False\n18:     description = _(\"A JSON object\")\n19:     default_error_messages = {\n20:         \"invalid\": _(\"Value must be valid JSON.\"),\n21:     }\n22:     _default_hint = (\"dict\", \"{}\")\n23: \n24:     def __init__(\n25:         self,\n26:         verbose_name=None,\n27:         name=None,\n28:         encoder=None,\n29:         decoder=None,\n30:         **kwargs,\n31:     ):\n32:         if encoder and not callable(encoder):\n33:             raise ValueError(\"The encoder parameter must be a callable object.\")\n34:         if decoder and not callable(decoder):\n35:             raise ValueError(\"The decoder parameter must be a callable object.\")\n36:         self.encoder = encoder\n37:         self.decoder = decoder\n38:         super().__init__(verbose_name, name, **kwargs)\n39: \n40:     def check(self, **kwargs):\n41:         errors = super().check(**kwargs)\n42:         databases = kwargs.get(\"databases\") or []\n43:         errors.extend(self._check_supported(databases))\n44:         return errors\n45: \n46:     def _check_supported(self, databases):\n47:         errors = []\n48:         for db in databases:\n49:             if not router.allow_migrate_model(db, self.model):\n50:                 continue\n51:             connection = connections[db]\n52:             if (\n53:                 self.model._meta.required_db_vendor\n54:                 and self.model._meta.required_db_vendor != connection.vendor\n55:             ):\n56:                 continue\n57:             if not (\n58:                 \"supports_json_field\" in self.model._meta.required_db_features\n59:                 or connection.features.supports_json_field\n60:             ):\n61:                 errors.append(\n62:                     checks.Error(\n63:                         \"%s does not support JSONFields.\" % connection.display_name,\n64:                         obj=self.model,\n65:                         id=\"fields.E180\",\n66:                     )\n67:                 )\n68:         return errors\n69: \n70:     def deconstruct(self):\n71:         name, path, args, kwargs = super().deconstruct()\n72:         if self.encoder is not None:\n73:             kwargs[\"encoder\"] = self.encoder\n74:         if self.decoder is not None:\n75:             kwargs[\"decoder\"] = self.decoder\n76:         return name, path, args, kwargs\n77: \n78:     def from_db_value(self, value, expression, connection):\n79:         if value is None:\n80:             return value\n81:         # Some backends (SQLite at least) extract non-string values in their\n82:         # SQL datatypes.\n83:         if isinstance(expression, KeyTransform) and not isinstance(value, str):\n84:             return value\n85:         try:\n86:             return json.loads(value, cls=self.decoder)\n87:         except json.JSONDecodeError:\n88:             return value\n89: \n90:     def get_internal_type(self):\n91:         return \"JSONField\"\n92: \n93:     def get_prep_value(self, value):\n94:         if value is None:\n95:             return value\n96:         return json.dumps(value, cls=self.encoder)\n97: \n98:     def get_transform(self, name):\n99:         transform = super().get_transform(name)\n100:         if transform:\n101:             return transform\n102:         return KeyTransformFactory(name)\n103: \n104:     def validate(self, value, model_instance):\n105:         super().validate(value, model_instance)\n106:         try:\n107:             json.dumps(value, cls=self.encoder)\n108:         except TypeError:\n109:             raise exceptions.ValidationError(\n110:                 self.error_messages[\"invalid\"],\n111:                 code=\"invalid\",\n112:                 params={\"value\": value},\n113:             )\n114: \n115:     def value_to_string(self, obj):\n116:         return self.value_from_object(obj)\n117: \n118:     def formfield(self, **kwargs):\n119:         return super().formfield(\n120:             **{\n121:                 \"form_class\": forms.JSONField,\n122:                 \"encoder\": self.encoder,\n123:                 \"decoder\": self.decoder,\n124:                 **kwargs,\n125:             }\n126:         )\n127: \n128: \n129: def compile_json_path(key_transforms, include_root=True):\nCode replaced for brevity.\n139: \n140: \n141: \n142: class DataContains(PostgresOperatorLookup):\nCode replaced for brevity.\n154: \n155: \n156: \n157: class ContainedBy(PostgresOperatorLookup):\nCode replaced for brevity.\n169: \n170: \n171: \n172: class HasKeyLookup(PostgresOperatorLookup):\n173:     logical_operator = None\n174: \n175:     def as_sql(self, compiler, connection, template=None):\n176:         # Process JSON path from the left-hand side.\n177:         if isinstance(self.lhs, KeyTransform):\n178:             lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(\n179:                 compiler, connection\n180:             )\n181:             lhs_json_path = compile_json_path(lhs_key_transforms)\n182:         else:\n183:             lhs, lhs_params = self.process_lhs(compiler, connection)\n184:             lhs_json_path = \"$\"\n185:         sql = template % lhs\n186:         # Process JSON path from the right-hand side.\n187:         rhs = self.rhs\n188:         rhs_params = []\n189:         if not isinstance(rhs, (list, tuple)):\n190:             rhs = [rhs]\n191:         for key in rhs:\n192:             if isinstance(key, KeyTransform):\n193:                 *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)\n194:             else:\n195:                 rhs_key_transforms = [key]\n196:             rhs_params.append(\n197:                 \"%s%s\"\n198:                 % (\n199:                     lhs_json_path,\n200:                     compile_json_path(rhs_key_transforms, include_root=False),\n201:                 )\n202:             )\n203:         # Add condition for each key.\n204:         if self.logical_operator:\n205:             sql = \"(%s)\" % self.logical_operator.join([sql] * len(rhs_params))\n206:         return sql, tuple(lhs_params) + tuple(rhs_params)\n207: \n208:     def as_mysql(self, compiler, connection):\n209:         return self.as_sql(\n210:             compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\"\n211:         )\n212: \n213:     def as_oracle(self, compiler, connection):\n214:         sql, params = self.as_sql(\n215:             compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\"\n216:         )\n217:         # Add paths directly into SQL because path expressions cannot be passed\n218:         # as bind variables on Oracle.\n219:         return sql % tuple(params), []\n220: \n221:     def as_postgresql(self, compiler, connection):\n222:         if isinstance(self.rhs, KeyTransform):\n223:             *_, rhs_key_transforms = self.rhs.preprocess_lhs(compiler, connection)\n224:             for key in rhs_key_transforms[:-1]:\n225:                 self.lhs = KeyTransform(key, self.lhs)\n226:             self.rhs = rhs_key_transforms[-1]\n227:         return super().as_postgresql(compiler, connection)\n228: \n229:     def as_sqlite(self, compiler, connection):\n230:         return self.as_sql(\n231:             compiler, connection, template=\"JSON_TYPE(%s, %%s) IS NOT NULL\"\n232:         )\n233: \n234: \n235: class HasKey(HasKeyLookup):\nCode replaced for brevity.\n238: \n239: \n240: \n241: class HasKeys(HasKeyLookup):\nCode replaced for brevity.\n247: \n248: \n249: \n250: class HasAnyKeys(HasKeys):\nCode replaced for brevity.\n253: \n254: \n255: \n256: class CaseInsensitiveMixin:\nCode replaced for brevity.\n274: \n275: \n276: \n277: class JSONExact(lookups.Exact):\nCode replaced for brevity.\n288: \n289: \n290: \n291: class JSONIContains(CaseInsensitiveMixin, lookups.IContains):\n292:     pass\n293: \n294: \n295: JSONField.register_lookup(DataContains)\n296: JSONField.register_lookup(ContainedBy)\n297: JSONField.register_lookup(HasKey)\n298: JSONField.register_lookup(HasKeys)\n299: JSONField.register_lookup(HasAnyKeys)\n300: JSONField.register_lookup(JSONExact)\n301: JSONField.register_lookup(JSONIContains)\n302: \n303: \n304: class KeyTransform(Transform):\nCode replaced for brevity.\n357: \n358: \n359: \n360: class KeyTextTransform(KeyTransform):\nCode replaced for brevity.\n362: \n363: \n364: \n365: class KeyTransformTextLookupMixin:\nCode replaced for brevity.\n384: \n385: \n386: \n387: class KeyTransformIsNull(lookups.IsNull):\n388:     # key__isnull=False is the same as has_key='key'\n389:     def as_oracle(self, compiler, connection):\n390:         sql, params = HasKey(\n391:             self.lhs.lhs,\n392:             self.lhs.key_name,\n393:         ).as_oracle(compiler, connection)\n394:         if not self.rhs:\n395:             return sql, params\n396:         # Column doesn't have a key or IS NULL.\n397:         lhs, lhs_params, _ = self.lhs.preprocess_lhs(compiler, connection)\n398:         return \"(NOT %s OR %s IS NULL)\" % (sql, lhs), tuple(params) + tuple(lhs_params)\n399: \n400:     def as_sqlite(self, compiler, connection):\n401:         template = \"JSON_TYPE(%s, %%s) IS NULL\"\n402:         if not self.rhs:\n403:             template = \"JSON_TYPE(%s, %%s) IS NOT NULL\"\n404:         return HasKey(self.lhs.lhs, self.lhs.key_name).as_sql(\n405:             compiler,\n406:             connection,\n407:             template=template,\n408:         )\n409: \n410: \n411: class KeyTransformIn(lookups.In):\nCode replaced for brevity.\n437: \n438: \n439: \n440: class KeyTransformExact(JSONExact):\n441:     def process_rhs(self, compiler, connection):\n442:         if isinstance(self.rhs, KeyTransform):\n443:             return super(lookups.Exact, self).process_rhs(compiler, connection)\n444:         rhs, rhs_params = super().process_rhs(compiler, connection)\n445:         if connection.vendor == \"oracle\":\n446:             func = []\n447:             sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"\n448:             for value in rhs_params:\n449:                 value = json.loads(value)\n450:                 if isinstance(value, (list, dict)):\n451:                     func.append(sql % \"JSON_QUERY\")\n452:                 else:\n453:                     func.append(sql % \"JSON_VALUE\")\n454:             rhs = rhs % tuple(func)\n455:         elif connection.vendor == \"sqlite\":\n456:             func = []\n457:             for value in rhs_params:\n458:                 if value in connection.ops.jsonfield_datatype_values:\n459:                     func.append(\"%s\")\n460:                 else:\n461:                     func.append(\"JSON_EXTRACT(%s, '$')\")\n462:             rhs = rhs % tuple(func)\n463:         return rhs, rhs_params\n464: \n465:     def as_oracle(self, compiler, connection):\n466:         rhs, rhs_params = super().process_rhs(compiler, connection)\n467:         if rhs_params == [\"null\"]:\n468:             # Field has key and it's NULL.\n469:             has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)\n470:             has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)\n471:             is_null_expr = self.lhs.get_lookup(\"isnull\")(self.lhs, True)\n472:             is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)\n473:             return (\n474:                 \"%s AND %s\" % (has_key_sql, is_null_sql),\n475:                 tuple(has_key_params) + tuple(is_null_params),\n476:             )\n477:         return super().as_sql(compiler, connection)\n478: \n479: \n480: ):\nCode replaced for brevity.\n483: \n484: \n485: \n486: ):\nCode replaced for brevity.\n489: \n490: \n491: \n492: class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):\nCode replaced for brevity.\n493: \n494: \n495: \n496: ):\nCode replaced for brevity.\n499: \n500: \n501: \n502: class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):\nCode replaced for brevity.\n503: \n504: \n505: \n506: ):\nCode replaced for brevity.\n509: \n510: \n511: \n512: class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):\n513:     pass\n514: \n515: \n516: ):\nCode replaced for brevity.\n519: \n520: \n521: \n522: class KeyTransformNumericLookupMixin:\nCode replaced for brevity.\n527: \n528: \n529: \n530: class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):\nCode replaced for brevity.\n531: \n532: \n533: \n534: class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):\nCode replaced for brevity.\n535: \n536: \n537: \n538: class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):\nCode replaced for brevity.\n539: \n540: \n541: \n542: class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):\nCode replaced for brevity.\n543: \n544: \n545: \n546: KeyTransform.register_lookup(KeyTransformIn)\n547: KeyTransform.register_lookup(KeyTransformExact)\n548: KeyTransform.register_lookup(KeyTransformIExact)\n549: KeyTransform.register_lookup(KeyTransformIsNull)\n550: KeyTransform.register_lookup(KeyTransformIContains)\n551: KeyTransform.register_lookup(KeyTransformStartsWith)\n552: KeyTransform.register_lookup(KeyTransformIStartsWith)\n553: KeyTransform.register_lookup(KeyTransformEndsWith)\n554: KeyTransform.register_lookup(KeyTransformIEndsWith)\n555: KeyTransform.register_lookup(KeyTransformRegex)\n556: KeyTransform.register_lookup(KeyTransformIRegex)\n557: \n558: KeyTransform.register_lookup(KeyTransformLt)\n559: KeyTransform.register_lookup(KeyTransformLte)\n560: KeyTransform.register_lookup(KeyTransformGt)\n561: KeyTransform.register_lookup(KeyTransformGte)\n562: \n563: \n564: class KeyTransformFactory:\nCode replaced for brevity.\n569: \n\n",
  "line_level_localization": [
    {
      "filename": "/django/db/models/fields/json.py",
      "suspect_lines": [
        196,
        197,
        198,
        199,
        200,
        201,
        202,
        390,
        404,
        469
      ]
    }
  ]
}