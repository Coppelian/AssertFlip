{
  "instance_id": "django__django-14170",
  "problem_statement": "Query optimization in YearLookup breaks filtering by \"__iso_year\"\nDescription\n\t \n\t\t(last modified by Florian Demmer)\n\t \nThe optimization to use BETWEEN instead of the EXTRACT operation in ​YearLookup is also registered for the ​\"__iso_year\" lookup, which breaks the functionality provided by ​ExtractIsoYear when used via the lookup.\nThis has unfortunately been broken ever since ExtractIsoYear was introduced in ​Django 2.2 via #28649 and wasn't easy to track down since ExtractIsoYear when used by itself eg. in an annotation works perfectly fine. Just when using the lookup in a filter, the optimization is used (even when explicitly using an annotation):\n# annotation works\n>>> qs = DTModel.objects.annotate(extracted=ExtractIsoYear('start_date')).only('id')\n>>> print(qs.query)\nSELECT \"db_functions_dtmodel\".\"id\", EXTRACT('isoyear' FROM \"db_functions_dtmodel\".\"start_date\") AS \"extracted\" FROM \"db_functions_dtmodel\"\n# explicit annotation used in filter does not use \"extracted\" and adds BETWEEN\n>>> print(qs.filter(extracted=2020).query)\nSELECT \"db_functions_dtmodel\".\"id\", EXTRACT('isoyear' FROM \"db_functions_dtmodel\".\"start_date\") AS \"extracted\" FROM \"db_functions_dtmodel\" WHERE \"db_functions_dtmodel\".\"start_date\" BETWEEN 2020-01-01 AND 2020-12-31\n# implicit lookup uses BETWEEN\n>>> print(DTModel.objects.filter(start_date__iso_year=2020).only('id').query)\nSELECT \"db_functions_dtmodel\".\"id\" FROM \"db_functions_dtmodel\" WHERE \"db_functions_dtmodel\".\"start_date\" BETWEEN 2020-01-01 AND 2020-12-31\nThis results in the wrong data being returned by filters using iso_year.\nThis PR fixes the behaviour, reverts the invalid changes to the tests and extends one test to catch this problem: ​https://github.com/django/django/pull/14157\n",
  "localized_code": "[start of django/db/backends/base/operations.py]\n1: import datetime\n2: import decimal\n3: from importlib import import_module\n4: \n5: import sqlparse\n6: \n7: from django.conf import settings\n8: from django.db import NotSupportedError, transaction\n9: from django.db.backends import utils\n10: from django.utils import timezone\n11: from django.utils.encoding import force_str\n12: \n13: \n14: class BaseDatabaseOperations:\n15:     \"\"\"\n16:     Encapsulate backend-specific differences, such as the way a backend\n17:     performs ordering or calculates the ID of a recently-inserted row.\n18:     \"\"\"\n19:     compiler_module = \"django.db.models.sql.compiler\"\n20: \n21:     # Integer field safe ranges by `internal_type` as documented\n22:     # in docs/ref/models/fields.txt.\n23:     integer_field_ranges = {\n24:         'SmallIntegerField': (-32768, 32767),\n25:         'IntegerField': (-2147483648, 2147483647),\n26:         'BigIntegerField': (-9223372036854775808, 9223372036854775807),\n27:         'PositiveBigIntegerField': (0, 9223372036854775807),\n28:         'PositiveSmallIntegerField': (0, 32767),\n29:         'PositiveIntegerField': (0, 2147483647),\n30:         'SmallAutoField': (-32768, 32767),\n31:         'AutoField': (-2147483648, 2147483647),\n32:         'BigAutoField': (-9223372036854775808, 9223372036854775807),\n33:     }\n34:     set_operators = {\n35:         'union': 'UNION',\n36:         'intersection': 'INTERSECT',\n37:         'difference': 'EXCEPT',\n38:     }\n39:     # Mapping of Field.get_internal_type() (typically the model field's class\n40:     # name) to the data type to use for the Cast() function, if different from\n41:     # DatabaseWrapper.data_types.\n42:     cast_data_types = {}\n43:     # CharField data type if the max_length argument isn't provided.\n44:     cast_char_field_without_max_length = None\n45: \n46:     # Start and end points for window expressions.\n47:     PRECEDING = 'PRECEDING'\n48:     FOLLOWING = 'FOLLOWING'\n49:     UNBOUNDED_PRECEDING = 'UNBOUNDED ' + PRECEDING\n50:     UNBOUNDED_FOLLOWING = 'UNBOUNDED ' + FOLLOWING\n51:     CURRENT_ROW = 'CURRENT ROW'\n52: \n53:     # Prefix for EXPLAIN queries, or None EXPLAIN isn't supported.\n54:     explain_prefix = None\n55: \n56:     def __init__(self, connection):\n57:         self.connection = connection\n58:         self._cache = None\n59: \n60:     def autoinc_sql(self, table, column):\n61:         \"\"\"\n62:         Return any SQL needed to support auto-incrementing primary keys, or\n63:         None if no SQL is necessary.\n64: \n65:         This SQL is executed when a table is created.\n66:         \"\"\"\n67:         return None\n68: \n69:     def bulk_batch_size(self, fields, objs):\n70:         \"\"\"\n71:         Return the maximum allowed batch size for the backend. The fields\n72:         are the fields going to be inserted in the batch, the objs contains\n73:         all the objects to be inserted.\n74:         \"\"\"\n75:         return len(objs)\n76: \n77:     def cache_key_culling_sql(self):\n78:         \"\"\"\n79:         Return an SQL query that retrieves the first cache key greater than the\n80:         n smallest.\n81: \n82:         This is used by the 'db' cache backend to determine where to start\n83:         culling.\n84:         \"\"\"\n85:         return \"SELECT cache_key FROM %s ORDER BY cache_key LIMIT 1 OFFSET %%s\"\n86: \n87:     def unification_cast_sql(self, output_field):\n88:         \"\"\"\n89:         Given a field instance, return the SQL that casts the result of a union\n90:         to that type. The resulting string should contain a '%s' placeholder\n91:         for the expression being cast.\n92:         \"\"\"\n93:         return '%s'\n94: \n95:     def date_extract_sql(self, lookup_type, field_name):\n96:         \"\"\"\n97:         Given a lookup_type of 'year', 'month', or 'day', return the SQL that\n98:         extracts a value from the given date field field_name.\n99:         \"\"\"\n100:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a date_extract_sql() method')\n101: \n102:     def date_trunc_sql(self, lookup_type, field_name, tzname=None):\n103:         \"\"\"\n104:         Given a lookup_type of 'year', 'month', or 'day', return the SQL that\n105:         truncates the given date or datetime field field_name to a date object\n106:         with only the given specificity.\n107: \n108:         If `tzname` is provided, the given value is truncated in a specific\n109:         timezone.\n110:         \"\"\"\n111:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a date_trunc_sql() method.')\n112: \n113:     def datetime_cast_date_sql(self, field_name, tzname):\n114:         \"\"\"\n115:         Return the SQL to cast a datetime value to date value.\n116:         \"\"\"\n117:         raise NotImplementedError(\n118:             'subclasses of BaseDatabaseOperations may require a '\n119:             'datetime_cast_date_sql() method.'\n120:         )\n121: \n122:     def datetime_cast_time_sql(self, field_name, tzname):\n123:         \"\"\"\n124:         Return the SQL to cast a datetime value to time value.\n125:         \"\"\"\n126:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_cast_time_sql() method')\n127: \n128:     def datetime_extract_sql(self, lookup_type, field_name, tzname):\n129:         \"\"\"\n130:         Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or\n131:         'second', return the SQL that extracts a value from the given\n132:         datetime field field_name.\n133:         \"\"\"\n134:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_extract_sql() method')\n135: \n136:     def datetime_trunc_sql(self, lookup_type, field_name, tzname):\n137:         \"\"\"\n138:         Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or\n139:         'second', return the SQL that truncates the given datetime field\n140:         field_name to a datetime object with only the given specificity.\n141:         \"\"\"\n142:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_trunc_sql() method')\n143: \n144:     def time_trunc_sql(self, lookup_type, field_name, tzname=None):\n145:         \"\"\"\n146:         Given a lookup_type of 'hour', 'minute' or 'second', return the SQL\n147:         that truncates the given time or datetime field field_name to a time\n148:         object with only the given specificity.\n149: \n150:         If `tzname` is provided, the given value is truncated in a specific\n151:         timezone.\n152:         \"\"\"\n153:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a time_trunc_sql() method')\n154: \n155:     def time_extract_sql(self, lookup_type, field_name):\n156:         \"\"\"\n157:         Given a lookup_type of 'hour', 'minute', or 'second', return the SQL\n158:         that extracts a value from the given time field field_name.\n159:         \"\"\"\n160:         return self.date_extract_sql(lookup_type, field_name)\n161: \n162:     def deferrable_sql(self):\n163:         \"\"\"\n164:         Return the SQL to make a constraint \"initially deferred\" during a\n165:         CREATE TABLE statement.\n166:         \"\"\"\n167:         return ''\n168: \n169:     def distinct_sql(self, fields, params):\n170:         \"\"\"\n171:         Return an SQL DISTINCT clause which removes duplicate rows from the\n172:         result set. If any fields are given, only check the given fields for\n173:         duplicates.\n174:         \"\"\"\n175:         if fields:\n176:             raise NotSupportedError('DISTINCT ON fields is not supported by this database backend')\n177:         else:\n178:             return ['DISTINCT'], []\n179: \n180:     def fetch_returned_insert_columns(self, cursor, returning_params):\n181:         \"\"\"\n182:         Given a cursor object that has just performed an INSERT...RETURNING\n183:         statement into a table, return the newly created data.\n184:         \"\"\"\n185:         return cursor.fetchone()\n186: \n187:     def field_cast_sql(self, db_type, internal_type):\n188:         \"\"\"\n189:         Given a column type (e.g. 'BLOB', 'VARCHAR') and an internal type\n190:         (e.g. 'GenericIPAddressField'), return the SQL to cast it before using\n191:         it in a WHERE statement. The resulting string should contain a '%s'\n192:         placeholder for the column being searched against.\n193:         \"\"\"\n194:         return '%s'\n195: \n196:     def force_no_ordering(self):\n197:         \"\"\"\n198:         Return a list used in the \"ORDER BY\" clause to force no ordering at\n199:         all. Return an empty list to include nothing in the ordering.\n200:         \"\"\"\n201:         return []\n202: \n203:     def for_update_sql(self, nowait=False, skip_locked=False, of=(), no_key=False):\n204:         \"\"\"\n205:         Return the FOR UPDATE SQL clause to lock rows for an update operation.\n206:         \"\"\"\n207:         return 'FOR%s UPDATE%s%s%s' % (\n208:             ' NO KEY' if no_key else '',\n209:             ' OF %s' % ', '.join(of) if of else '',\n210:             ' NOWAIT' if nowait else '',\n211:             ' SKIP LOCKED' if skip_locked else '',\n212:         )\n213: \n214:     def _get_limit_offset_params(self, low_mark, high_mark):\n215:         offset = low_mark or 0\n216:         if high_mark is not None:\n217:             return (high_mark - offset), offset\n218:         elif offset:\n219:             return self.connection.ops.no_limit_value(), offset\n220:         return None, offset\n221: \n222:     def limit_offset_sql(self, low_mark, high_mark):\n223:         \"\"\"Return LIMIT/OFFSET SQL clause.\"\"\"\n224:         limit, offset = self._get_limit_offset_params(low_mark, high_mark)\n225:         return ' '.join(sql for sql in (\n226:             ('LIMIT %d' % limit) if limit else None,\n227:             ('OFFSET %d' % offset) if offset else None,\n228:         ) if sql)\n229: \n230:     def last_executed_query(self, cursor, sql, params):\n231:         \"\"\"\n232:         Return a string of the query last executed by the given cursor, with\n233:         placeholders replaced with actual values.\n234: \n235:         `sql` is the raw query containing placeholders and `params` is the\n236:         sequence of parameters. These are used by default, but this method\n237:         exists for database backends to provide a better implementation\n238:         according to their own quoting schemes.\n239:         \"\"\"\n240:         # Convert params to contain string values.\n241:         def to_string(s):\n242:             return force_str(s, strings_only=True, errors='replace')\n243:         if isinstance(params, (list, tuple)):\n244:             u_params = tuple(to_string(val) for val in params)\n245:         elif params is None:\n246:             u_params = ()\n247:         else:\n248:             u_params = {to_string(k): to_string(v) for k, v in params.items()}\n249: \n250:         return \"QUERY = %r - PARAMS = %r\" % (sql, u_params)\n251: \n252:     def last_insert_id(self, cursor, table_name, pk_name):\n253:         \"\"\"\n254:         Given a cursor object that has just performed an INSERT statement into\n255:         a table that has an auto-incrementing ID, return the newly created ID.\n256: \n257:         `pk_name` is the name of the primary-key column.\n258:         \"\"\"\n259:         return cursor.lastrowid\n260: \n261:     def lookup_cast(self, lookup_type, internal_type=None):\n262:         \"\"\"\n263:         Return the string to use in a query when performing lookups\n264:         (\"contains\", \"like\", etc.). It should contain a '%s' placeholder for\n265:         the column being searched against.\n266:         \"\"\"\n267:         return \"%s\"\n268: \n269:     def max_in_list_size(self):\n270:         \"\"\"\n271:         Return the maximum number of items that can be passed in a single 'IN'\n272:         list condition, or None if the backend does not impose a limit.\n273:         \"\"\"\n274:         return None\n275: \n276:     def max_name_length(self):\n277:         \"\"\"\n278:         Return the maximum length of table and column names, or None if there\n279:         is no limit.\n280:         \"\"\"\n281:         return None\n282: \n283:     def no_limit_value(self):\n284:         \"\"\"\n285:         Return the value to use for the LIMIT when we are wanting \"LIMIT\n286:         infinity\". Return None if the limit clause can be omitted in this case.\n287:         \"\"\"\n288:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a no_limit_value() method')\n289: \n290:     def pk_default_value(self):\n291:         \"\"\"\n292:         Return the value to use during an INSERT statement to specify that\n293:         the field should use its default value.\n294:         \"\"\"\n295:         return 'DEFAULT'\n296: \n297:     def prepare_sql_script(self, sql):\n298:         \"\"\"\n299:         Take an SQL script that may contain multiple lines and return a list\n300:         of statements to feed to successive cursor.execute() calls.\n301: \n302:         Since few databases are able to process raw SQL scripts in a single\n303:         cursor.execute() call and PEP 249 doesn't talk about this use case,\n304:         the default implementation is conservative.\n305:         \"\"\"\n306:         return [\n307:             sqlparse.format(statement, strip_comments=True)\n308:             for statement in sqlparse.split(sql) if statement\n309:         ]\n310: \n311:     def process_clob(self, value):\n312:         \"\"\"\n313:         Return the value of a CLOB column, for backends that return a locator\n314:         object that requires additional processing.\n315:         \"\"\"\n316:         return value\n317: \n318:     def return_insert_columns(self, fields):\n319:         \"\"\"\n320:         For backends that support returning columns as part of an insert query,\n321:         return the SQL and params to append to the INSERT query. The returned\n322:         fragment should contain a format string to hold the appropriate column.\n323:         \"\"\"\n324:         pass\n325: \n326:     def compiler(self, compiler_name):\n327:         \"\"\"\n328:         Return the SQLCompiler class corresponding to the given name,\n329:         in the namespace corresponding to the `compiler_module` attribute\n330:         on this backend.\n331:         \"\"\"\n332:         if self._cache is None:\n333:             self._cache = import_module(self.compiler_module)\n334:         return getattr(self._cache, compiler_name)\n335: \n336:     def quote_name(self, name):\n337:         \"\"\"\n338:         Return a quoted version of the given table, index, or column name. Do\n339:         not quote the given name if it's already been quoted.\n340:         \"\"\"\n341:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a quote_name() method')\n342: \n343:     def regex_lookup(self, lookup_type):\n344:         \"\"\"\n345:         Return the string to use in a query when performing regular expression\n346:         lookups (using \"regex\" or \"iregex\"). It should contain a '%s'\n347:         placeholder for the column being searched against.\n348: \n349:         If the feature is not supported (or part of it is not supported), raise\n350:         NotImplementedError.\n351:         \"\"\"\n352:         raise NotImplementedError('subclasses of BaseDatabaseOperations may require a regex_lookup() method')\n353: \n354:     def savepoint_create_sql(self, sid):\n355:         \"\"\"\n356:         Return the SQL for starting a new savepoint. Only required if the\n357:         \"uses_savepoints\" feature is True. The \"sid\" parameter is a string\n358:         for the savepoint id.\n359:         \"\"\"\n360:         return \"SAVEPOINT %s\" % self.quote_name(sid)\n361: \n362:     def savepoint_commit_sql(self, sid):\n363:         \"\"\"\n364:         Return the SQL for committing the given savepoint.\n365:         \"\"\"\n366:         return \"RELEASE SAVEPOINT %s\" % self.quote_name(sid)\n367: \n368:     def savepoint_rollback_sql(self, sid):\n369:         \"\"\"\n370:         Return the SQL for rolling back the given savepoint.\n371:         \"\"\"\n372:         return \"ROLLBACK TO SAVEPOINT %s\" % self.quote_name(sid)\n373: \n374:     def set_time_zone_sql(self):\n375:         \"\"\"\n376:         Return the SQL that will set the connection's time zone.\n377: \n378:         Return '' if the backend doesn't support time zones.\n379:         \"\"\"\n380:         return ''\n381: \n382:     def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):\n383:         \"\"\"\n384:         Return a list of SQL statements required to remove all data from\n385:         the given database tables (without actually removing the tables\n386:         themselves).\n387: \n388:         The `style` argument is a Style object as returned by either\n389:         color_style() or no_style() in django.core.management.color.\n390: \n391:         If `reset_sequences` is True, the list includes SQL statements required\n392:         to reset the sequences.\n393: \n394:         The `allow_cascade` argument determines whether truncation may cascade\n395:         to tables with foreign keys pointing the tables being truncated.\n396:         PostgreSQL requires a cascade even if these tables are empty.\n397:         \"\"\"\n398:         raise NotImplementedError('subclasses of BaseDatabaseOperations must provide an sql_flush() method')\n399: \n400:     def execute_sql_flush(self, sql_list):\n401:         \"\"\"Execute a list of SQL statements to flush the database.\"\"\"\n402:         with transaction.atomic(\n403:             using=self.connection.alias,\n404:             savepoint=self.connection.features.can_rollback_ddl,\n405:         ):\n406:             with self.connection.cursor() as cursor:\n407:                 for sql in sql_list:\n408:                     cursor.execute(sql)\n409: \n410:     def sequence_reset_by_name_sql(self, style, sequences):\n411:         \"\"\"\n412:         Return a list of the SQL statements required to reset sequences\n413:         passed in `sequences`.\n414: \n415:         The `style` argument is a Style object as returned by either\n416:         color_style() or no_style() in django.core.management.color.\n417:         \"\"\"\n418:         return []\n419: \n420:     def sequence_reset_sql(self, style, model_list):\n421:         \"\"\"\n422:         Return a list of the SQL statements required to reset sequences for\n423:         the given models.\n424: \n425:         The `style` argument is a Style object as returned by either\n426:         color_style() or no_style() in django.core.management.color.\n427:         \"\"\"\n428:         return []  # No sequence reset required by default.\n429: \n430:     def start_transaction_sql(self):\n431:         \"\"\"Return the SQL statement required to start a transaction.\"\"\"\n432:         return \"BEGIN;\"\n433: \n434:     def end_transaction_sql(self, success=True):\n435:         \"\"\"Return the SQL statement required to end a transaction.\"\"\"\n436:         if not success:\n437:             return \"ROLLBACK;\"\n438:         return \"COMMIT;\"\n439: \n440:     def tablespace_sql(self, tablespace, inline=False):\n441:         \"\"\"\n442:         Return the SQL that will be used in a query to define the tablespace.\n443: \n444:         Return '' if the backend doesn't support tablespaces.\n445: \n446:         If `inline` is True, append the SQL to a row; otherwise append it to\n447:         the entire CREATE TABLE or CREATE INDEX statement.\n448:         \"\"\"\n449:         return ''\n450: \n451:     def prep_for_like_query(self, x):\n452:         \"\"\"Prepare a value for use in a LIKE query.\"\"\"\n453:         return str(x).replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", r\"\\%\").replace(\"_\", r\"\\_\")\n454: \n455:     # Same as prep_for_like_query(), but called for \"iexact\" matches, which\n456:     # need not necessarily be implemented using \"LIKE\" in the backend.\n457:     prep_for_iexact_query = prep_for_like_query\n458: \n459:     def validate_autopk_value(self, value):\n460:         \"\"\"\n461:         Certain backends do not accept some values for \"serial\" fields\n462:         (for example zero in MySQL). Raise a ValueError if the value is\n463:         invalid, otherwise return the validated value.\n464:         \"\"\"\n465:         return value\n466: \n467:     def adapt_unknown_value(self, value):\n468:         \"\"\"\n469:         Transform a value to something compatible with the backend driver.\n470: \n471:         This method only depends on the type of the value. It's designed for\n472:         cases where the target type isn't known, such as .raw() SQL queries.\n473:         As a consequence it may not work perfectly in all circumstances.\n474:         \"\"\"\n475:         if isinstance(value, datetime.datetime):   # must be before date\n476:             return self.adapt_datetimefield_value(value)\n477:         elif isinstance(value, datetime.date):\n478:             return self.adapt_datefield_value(value)\n479:         elif isinstance(value, datetime.time):\n480:             return self.adapt_timefield_value(value)\n481:         elif isinstance(value, decimal.Decimal):\n482:             return self.adapt_decimalfield_value(value)\n483:         else:\n484:             return value\n485: \n486:     def adapt_datefield_value(self, value):\n487:         \"\"\"\n488:         Transform a date value to an object compatible with what is expected\n489:         by the backend driver for date columns.\n490:         \"\"\"\n491:         if value is None:\n492:             return None\n493:         return str(value)\n494: \n495:     def adapt_datetimefield_value(self, value):\n496:         \"\"\"\n497:         Transform a datetime value to an object compatible with what is expected\n498:         by the backend driver for datetime columns.\n499:         \"\"\"\n500:         if value is None:\n501:             return None\n502:         return str(value)\n503: \n504:     def adapt_timefield_value(self, value):\n505:         \"\"\"\n506:         Transform a time value to an object compatible with what is expected\n507:         by the backend driver for time columns.\n508:         \"\"\"\n509:         if value is None:\n510:             return None\n511:         if timezone.is_aware(value):\n512:             raise ValueError(\"Django does not support timezone-aware times.\")\n513:         return str(value)\n514: \n515:     def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):\n516:         \"\"\"\n517:         Transform a decimal.Decimal value to an object compatible with what is\n518:         expected by the backend driver for decimal (numeric) columns.\n519:         \"\"\"\n520:         return utils.format_number(value, max_digits, decimal_places)\n521: \n522:     def adapt_ipaddressfield_value(self, value):\n523:         \"\"\"\n524:         Transform a string representation of an IP address into the expected\n525:         type for the backend driver.\n526:         \"\"\"\n527:         return value or None\n528: \n529:     def year_lookup_bounds_for_date_field(self, value):\n530:         \"\"\"\n531:         Return a two-elements list with the lower and upper bound to be used\n532:         with a BETWEEN operator to query a DateField value using a year\n533:         lookup.\n534: \n535:         `value` is an int, containing the looked-up year.\n536:         \"\"\"\n537:         first = datetime.date(value, 1, 1)\n538:         second = datetime.date(value, 12, 31)\n539:         first = self.adapt_datefield_value(first)\n540:         second = self.adapt_datefield_value(second)\n541:         return [first, second]\n542: \n543:     def year_lookup_bounds_for_datetime_field(self, value):\n544:         \"\"\"\n545:         Return a two-elements list with the lower and upper bound to be used\n546:         with a BETWEEN operator to query a DateTimeField value using a year\n547:         lookup.\n548: \n549:         `value` is an int, containing the looked-up year.\n550:         \"\"\"\n551:         first = datetime.datetime(value, 1, 1)\n552:         second = datetime.datetime(value, 12, 31, 23, 59, 59, 999999)\n553:         if settings.USE_TZ:\n... Code Truncated ...\n\n[start of django/db/models/lookups.py]\n1: import itertools\n2: import math\n3: from copy import copy\n4: \n5: from django.core.exceptions import EmptyResultSet\n6: from django.db.models.expressions import Case, Exists, Func, Value, When\n7: from django.db.models.fields import (\n8:     CharField, DateTimeField, Field, IntegerField, UUIDField,\n9: )\n10: from django.db.models.query_utils import RegisterLookupMixin\n11: from django.utils.datastructures import OrderedSet\n12: from django.utils.functional import cached_property\n13: from django.utils.hashable import make_hashable\n14: \n15: \n16: class Lookup:\n17:     lookup_name = None\n18:     prepare_rhs = True\n19:     can_use_none_as_rhs = False\n20: \n21:     def __init__(self, lhs, rhs):\n22:         self.lhs, self.rhs = lhs, rhs\n23:         self.rhs = self.get_prep_lookup()\n24:         if hasattr(self.lhs, 'get_bilateral_transforms'):\n25:             bilateral_transforms = self.lhs.get_bilateral_transforms()\n26:         else:\n27:             bilateral_transforms = []\n28:         if bilateral_transforms:\n29:             # Warn the user as soon as possible if they are trying to apply\n30:             # a bilateral transformation on a nested QuerySet: that won't work.\n31:             from django.db.models.sql.query import (  # avoid circular import\n32:                 Query,\n33:             )\n34:             if isinstance(rhs, Query):\n35:                 raise NotImplementedError(\"Bilateral transformations on nested querysets are not implemented.\")\n36:         self.bilateral_transforms = bilateral_transforms\n37: \n38:     def apply_bilateral_transforms(self, value):\n39:         for transform in self.bilateral_transforms:\n40:             value = transform(value)\n41:         return value\n42: \n43:     def batch_process_rhs(self, compiler, connection, rhs=None):\n44:         if rhs is None:\n45:             rhs = self.rhs\n46:         if self.bilateral_transforms:\n47:             sqls, sqls_params = [], []\n48:             for p in rhs:\n49:                 value = Value(p, output_field=self.lhs.output_field)\n50:                 value = self.apply_bilateral_transforms(value)\n51:                 value = value.resolve_expression(compiler.query)\n52:                 sql, sql_params = compiler.compile(value)\n53:                 sqls.append(sql)\n54:                 sqls_params.extend(sql_params)\n55:         else:\n56:             _, params = self.get_db_prep_lookup(rhs, connection)\n57:             sqls, sqls_params = ['%s'] * len(params), params\n58:         return sqls, sqls_params\n59: \n60:     def get_source_expressions(self):\n61:         if self.rhs_is_direct_value():\n62:             return [self.lhs]\n63:         return [self.lhs, self.rhs]\n64: \n65:     def set_source_expressions(self, new_exprs):\n66:         if len(new_exprs) == 1:\n67:             self.lhs = new_exprs[0]\n68:         else:\n69:             self.lhs, self.rhs = new_exprs\n70: \n71:     def get_prep_lookup(self):\n72:         if hasattr(self.rhs, 'resolve_expression'):\n73:             return self.rhs\n74:         if self.prepare_rhs and hasattr(self.lhs.output_field, 'get_prep_value'):\n75:             return self.lhs.output_field.get_prep_value(self.rhs)\n76:         return self.rhs\n77: \n78:     def get_db_prep_lookup(self, value, connection):\n79:         return ('%s', [value])\n80: \n81:     def process_lhs(self, compiler, connection, lhs=None):\n82:         lhs = lhs or self.lhs\n83:         if hasattr(lhs, 'resolve_expression'):\n84:             lhs = lhs.resolve_expression(compiler.query)\n85:         return compiler.compile(lhs)\n86: \n87:     def process_rhs(self, compiler, connection):\n88:         value = self.rhs\n89:         if self.bilateral_transforms:\n90:             if self.rhs_is_direct_value():\n91:                 # Do not call get_db_prep_lookup here as the value will be\n92:                 # transformed before being used for lookup\n93:                 value = Value(value, output_field=self.lhs.output_field)\n94:             value = self.apply_bilateral_transforms(value)\n95:             value = value.resolve_expression(compiler.query)\n96:         if hasattr(value, 'as_sql'):\n97:             return compiler.compile(value)\n98:         else:\n99:             return self.get_db_prep_lookup(value, connection)\n100: \n101:     def rhs_is_direct_value(self):\n102:         return not hasattr(self.rhs, 'as_sql')\n103: \n104:     def relabeled_clone(self, relabels):\n105:         new = copy(self)\n106:         new.lhs = new.lhs.relabeled_clone(relabels)\n107:         if hasattr(new.rhs, 'relabeled_clone'):\n108:             new.rhs = new.rhs.relabeled_clone(relabels)\n109:         return new\n110: \n111:     def get_group_by_cols(self, alias=None):\n112:         cols = self.lhs.get_group_by_cols()\n113:         if hasattr(self.rhs, 'get_group_by_cols'):\n114:             cols.extend(self.rhs.get_group_by_cols())\n115:         return cols\n116: \n117:     def as_sql(self, compiler, connection):\n118:         raise NotImplementedError\n119: \n120:     def as_oracle(self, compiler, connection):\n121:         # Oracle doesn't allow EXISTS() to be compared to another expression\n122:         # unless it's wrapped in a CASE WHEN.\n123:         wrapped = False\n124:         exprs = []\n125:         for expr in (self.lhs, self.rhs):\n126:             if isinstance(expr, Exists):\n127:                 expr = Case(When(expr, then=True), default=False)\n128:                 wrapped = True\n129:             exprs.append(expr)\n130:         lookup = type(self)(*exprs) if wrapped else self\n131:         return lookup.as_sql(compiler, connection)\n132: \n133:     @cached_property\n134:     def contains_aggregate(self):\n135:         return self.lhs.contains_aggregate or getattr(self.rhs, 'contains_aggregate', False)\n136: \n137:     @cached_property\n138:     def contains_over_clause(self):\n139:         return self.lhs.contains_over_clause or getattr(self.rhs, 'contains_over_clause', False)\n140: \n141:     @property\n142:     def is_summary(self):\n143:         return self.lhs.is_summary or getattr(self.rhs, 'is_summary', False)\n144: \n145:     @property\n146:     def identity(self):\n147:         return self.__class__, self.lhs, self.rhs\n148: \n149:     def __eq__(self, other):\n150:         if not isinstance(other, Lookup):\n151:             return NotImplemented\n152:         return self.identity == other.identity\n153: \n154:     def __hash__(self):\n155:         return hash(make_hashable(self.identity))\n156: \n157: \n158: class Transform(RegisterLookupMixin, Func):\nCode replaced for brevity.\n177: \n178: \n179: \n180: class BuiltinLookup(Lookup):\nCode replaced for brevity.\n198: \n199: \n200: \n201: class FieldGetDbPrepValueMixin:\nCode replaced for brevity.\n218: \n219: \n220: \n221: class FieldGetDbPrepValueIterableMixin(FieldGetDbPrepValueMixin):\nCode replaced for brevity.\n269: \n270: \n271: \n272: class PostgresOperatorLookup(FieldGetDbPrepValueMixin, Lookup):\nCode replaced for brevity.\n280: \n281: \n282: \n283: @Field.register_lookup\n284: class Exact(FieldGetDbPrepValueMixin, BuiltinLookup):\nCode replaced for brevity.\n313: \n314: \n315: \n316: @Field.register_lookup\n317: class IExact(BuiltinLookup):\nCode replaced for brevity.\n325: \n326: \n327: \n328: @Field.register_lookup\n329: class GreaterThan(FieldGetDbPrepValueMixin, BuiltinLookup):\nCode replaced for brevity.\n330: \n331: \n332: \n333: @Field.register_lookup\n334: class GreaterThanOrEqual(FieldGetDbPrepValueMixin, BuiltinLookup):\nCode replaced for brevity.\n335: \n336: \n337: \n338: @Field.register_lookup\n339: class LessThan(FieldGetDbPrepValueMixin, BuiltinLookup):\n340:     lookup_name = 'lt'\n341: \n342: \n343: @Field.register_lookup\n344: class LessThanOrEqual(FieldGetDbPrepValueMixin, BuiltinLookup):\nCode replaced for brevity.\n345: \n346: \n347: \n348: class IntegerFieldFloatRounding:\nCode replaced for brevity.\n356: \n357: \n358: \n359: @IntegerField.register_lookup\n360: class IntegerGreaterThanOrEqual(IntegerFieldFloatRounding, GreaterThanOrEqual):\nCode replaced for brevity.\n361: \n362: \n363: \n364: @IntegerField.register_lookup\n365: class IntegerLessThan(IntegerFieldFloatRounding, LessThan):\n366:     pass\n367: \n368: \n369: @Field.register_lookup\n370: class In(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\nCode replaced for brevity.\n432: \n433: \n434: \n435: class PatternLookup(BuiltinLookup):\nCode replaced for brevity.\n459: \n460: \n461: \n462: @Field.register_lookup\n463: class Contains(PatternLookup):\n464:     lookup_name = 'contains'\n465: \n466: \n467: @Field.register_lookup\n468: class IContains(Contains):\n469:     lookup_name = 'icontains'\n470: \n471: \n472: @Field.register_lookup\n473: class StartsWith(PatternLookup):\nCode replaced for brevity.\n475: \n476: \n477: \n478: @Field.register_lookup\n479: class IStartsWith(StartsWith):\n480:     lookup_name = 'istartswith'\n481: \n482: \n483: @Field.register_lookup\n484: class EndsWith(PatternLookup):\nCode replaced for brevity.\n486: \n487: \n488: \n489: @Field.register_lookup\n490: class IEndsWith(EndsWith):\n491:     lookup_name = 'iendswith'\n492: \n493: \n494: @Field.register_lookup\n495: class Range(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\nCode replaced for brevity.\n499: \n500: \n501: \n502: @Field.register_lookup\n503: class IsNull(BuiltinLookup):\nCode replaced for brevity.\n517: \n518: \n519: \n520: @Field.register_lookup\n521: class Regex(BuiltinLookup):\nCode replaced for brevity.\n532: \n533: \n534: \n535: @Field.register_lookup\n536: class IRegex(Regex):\n537:     lookup_name = 'iregex'\n538: \n539: \n540: class YearLookup(Lookup):\n541:     def year_lookup_bounds(self, connection, year):\n542:         output_field = self.lhs.lhs.output_field\n543:         if isinstance(output_field, DateTimeField):\n544:             bounds = connection.ops.year_lookup_bounds_for_datetime_field(year)\n545:         else:\n546:             bounds = connection.ops.year_lookup_bounds_for_date_field(year)\n547:         return bounds\n548: \n549:     def as_sql(self, compiler, connection):\n550:         # Avoid the extract operation if the rhs is a direct value to allow\n551:         # indexes to be used.\n552:         if self.rhs_is_direct_value():\n553:             # Skip the extract part by directly using the originating field,\n554:             # that is self.lhs.lhs.\n555:             lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs)\n556:             rhs_sql, _ = self.process_rhs(compiler, connection)\n557:             rhs_sql = self.get_direct_rhs_sql(connection, rhs_sql)\n558:             start, finish = self.year_lookup_bounds(connection, self.rhs)\n559:             params.extend(self.get_bound_params(start, finish))\n560:             return '%s %s' % (lhs_sql, rhs_sql), params\n561:         return super().as_sql(compiler, connection)\n562: \n563:     def get_direct_rhs_sql(self, connection, rhs):\n564:         return connection.operators[self.lookup_name] % rhs\n565: \n566:     def get_bound_params(self, start, finish):\n567:         raise NotImplementedError(\n568:             'subclasses of YearLookup must provide a get_bound_params() method'\n569:         )\n570: \n571: \n572: class YearExact(YearLookup, Exact):\nCode replaced for brevity.\n577: \n578: \n579: \n580: class YearGt(YearLookup, GreaterThan):\nCode replaced for brevity.\n582: \n583: \n584: \n585: class YearGte(YearLookup, GreaterThanOrEqual):\nCode replaced for brevity.\n587: \n588: \n589: \n590: class YearLt(YearLookup, LessThan):\nCode replaced for brevity.\n592: \n593: \n594: \n595: class YearLte(YearLookup, LessThanOrEqual):\nCode replaced for brevity.\n597: \n598: \n599: \n600: class UUIDTextMixin:\nCode replaced for brevity.\n612: \n613: \n614: \n615: @UUIDField.register_lookup\n616: class UUIDIExact(UUIDTextMixin, IExact):\n617:     pass\n618: \n619: \n620: @UUIDField.register_lookup\n621: class UUIDContains(UUIDTextMixin, Contains):\n622:     pass\n623: \n624: \n625: @UUIDField.register_lookup\n626: class UUIDIContains(UUIDTextMixin, IContains):\n627:     pass\n628: \n629: \n630: @UUIDField.register_lookup\n631: class UUIDStartsWith(UUIDTextMixin, StartsWith):\n632:     pass\n633: \n634: \n635: @UUIDField.register_lookup\n636: class UUIDIStartsWith(UUIDTextMixin, IStartsWith):\n637:     pass\n638: \n639: \n640: @UUIDField.register_lookup\n641: class UUIDEndsWith(UUIDTextMixin, EndsWith):\n642:     pass\n643: \n644: \n645: @UUIDField.register_lookup\n646: class UUIDIEndsWith(UUIDTextMixin, IEndsWith):\n647:     pass\n\n",
  "line_level_localization": [
    {
      "filename": "/django/db/backends/base/operations.py",
      "suspect_lines": [
        529,
        537,
        538,
        543,
        551,
        552
      ]
    },
    {
      "filename": "/django/db/models/lookups.py",
      "suspect_lines": [
        544,
        546
      ]
    }
  ]
}