{
  "instance_id": "pydata__xarray-3095",
  "problem_statement": "REGRESSION: copy(deep=True) casts unicode indices to object\nDataset.copy(deep=True) and DataArray.copy (deep=True/False) accidentally cast IndexVariable's with dtype='<U*' to object. Same applies to copy.copy() and copy.deepcopy().\r\n\r\nThis is a regression in xarray >= 0.12.2. xarray 0.12.1 and earlier are unaffected.\r\n\r\n```\r\n\r\nIn [1]: ds = xarray.Dataset(\r\n   ...:     coords={'x': ['foo'], 'y': ('x', ['bar'])},\r\n   ...:     data_vars={'z': ('x', ['baz'])})                                                              \r\n\r\nIn [2]: ds                                                                                                                                                                                                                     \r\nOut[2]: \r\n<xarray.Dataset>\r\nDimensions:  (x: 1)\r\nCoordinates:\r\n  * x        (x) <U3 'foo'\r\n    y        (x) <U3 'bar'\r\nData variables:\r\n    z        (x) <U3 'baz'\r\n\r\nIn [3]: ds.copy()                                                                                                                                                                                                              \r\nOut[3]: \r\n<xarray.Dataset>\r\nDimensions:  (x: 1)\r\nCoordinates:\r\n  * x        (x) <U3 'foo'\r\n    y        (x) <U3 'bar'\r\nData variables:\r\n    z        (x) <U3 'baz'\r\n\r\nIn [4]: ds.copy(deep=True)                                                                                                                                                                                                     \r\nOut[4]: \r\n<xarray.Dataset>\r\nDimensions:  (x: 1)\r\nCoordinates:\r\n  * x        (x) object 'foo'\r\n    y        (x) <U3 'bar'\r\nData variables:\r\n    z        (x) <U3 'baz'\r\n\r\nIn [5]: ds.z                                                                                                                                                                                                                   \r\nOut[5]: \r\n<xarray.DataArray 'z' (x: 1)>\r\narray(['baz'], dtype='<U3')\r\nCoordinates:\r\n  * x        (x) <U3 'foo'\r\n    y        (x) <U3 'bar'\r\n\r\nIn [6]: ds.z.copy()                                                                                                                                                                                                            \r\nOut[6]: \r\n<xarray.DataArray 'z' (x: 1)>\r\narray(['baz'], dtype='<U3')\r\nCoordinates:\r\n  * x        (x) object 'foo'\r\n    y        (x) <U3 'bar'\r\n\r\nIn [7]: ds.z.copy(deep=True)                                                                                                                                                                                                   \r\nOut[7]: \r\n<xarray.DataArray 'z' (x: 1)>\r\narray(['baz'], dtype='<U3')\r\nCoordinates:\r\n  * x        (x) object 'foo'\r\n    y        (x) <U3 'bar'\r\n```\n",
  "localized_code": "[start of xarray/core/indexing.py]\n1: import functools\n2: import operator\n3: from collections import defaultdict\n4: from contextlib import suppress\n5: from datetime import timedelta\n6: from typing import Sequence\n7: \n8: import numpy as np\n9: import pandas as pd\n10: \n11: from . import duck_array_ops, nputils, utils\n12: from .pycompat import dask_array_type, integer_types\n13: from .utils import is_dict_like\n14: \n15: \n16: def expanded_indexer(key, ndim):\n17:     \"\"\"Given a key for indexing an ndarray, return an equivalent key which is a\n18:     tuple with length equal to the number of dimensions.\n19: \n20:     The expansion is done by replacing all `Ellipsis` items with the right\n21:     number of full slices and then padding the key with full slices so that it\n22:     reaches the appropriate dimensionality.\n23:     \"\"\"\n24:     if not isinstance(key, tuple):\n25:         # numpy treats non-tuple keys equivalent to tuples of length 1\n26:         key = (key,)\n27:     new_key = []\n28:     # handling Ellipsis right is a little tricky, see:\n29:     # http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing\n30:     found_ellipsis = False\n31:     for k in key:\n32:         if k is Ellipsis:\n33:             if not found_ellipsis:\n34:                 new_key.extend((ndim + 1 - len(key)) * [slice(None)])\n35:                 found_ellipsis = True\n36:             else:\n37:                 new_key.append(slice(None))\n38:         else:\n39:             new_key.append(k)\n40:     if len(new_key) > ndim:\n41:         raise IndexError('too many indices')\n42:     new_key.extend((ndim - len(new_key)) * [slice(None)])\n43:     return tuple(new_key)\n44: \n45: \n46: def _expand_slice(slice_, size):\n47:     return np.arange(*slice_.indices(size))\n48: \n49: \n50: def _sanitize_slice_element(x):\n51:     from .variable import Variable\n52:     from .dataarray import DataArray\n53: \n54:     if isinstance(x, (Variable, DataArray)):\n55:         x = x.values\n56: \n57:     if isinstance(x, np.ndarray):\n58:         if x.ndim != 0:\n59:             raise ValueError('cannot use non-scalar arrays in a slice for '\n60:                              'xarray indexing: {}'.format(x))\n61:         x = x[()]\n62: \n63:     if isinstance(x, np.timedelta64):\n64:         # pandas does not support indexing with np.timedelta64 yet:\n65:         # https://github.com/pandas-dev/pandas/issues/20393\n66:         x = pd.Timedelta(x)\n67: \n68:     return x\n69: \n70: \n71: def _asarray_tuplesafe(values):\nCode replaced for brevity.\n86: \n87: \n88: \n89: def _is_nested_tuple(possible_tuple):\nCode replaced for brevity.\n92: \n93: \n94: \n95:     # (tolerance)\nCode replaced for brevity.\n103: \n104: \n105: \n106: def get_loc(index, label, method=None, tolerance=None):\nCode replaced for brevity.\n108: \n109: \n110: \n111: def get_indexer_nd(index, labels, method=None, tolerance=None):\nCode replaced for brevity.\n118: \n119: \n120: \n121:                           tolerance=None):\nCode replaced for brevity.\n192: \n193: \n194: \n195: def get_dim_indexers(data_obj, indexers):\nCode replaced for brevity.\n225: \n226: \n227: \n228: def remap_label_indexers(data_obj, indexers, method=None, tolerance=None):\nCode replaced for brevity.\n257: \n258: \n259: \n260: def slice_slice(old_slice, applied_slice, size):\nCode replaced for brevity.\n279: \n280: \n281: \n282: def _index_indexer_1d(old_indexer, applied_indexer, size):\nCode replaced for brevity.\n294: \n295: \n296: \n297: class ExplicitIndexer:\nCode replaced for brevity.\n318: \n319: \n320: \n321: def as_integer_or_none(value):\nCode replaced for brevity.\n322: \n323: \n324: \n325: def as_integer_slice(value):\nCode replaced for brevity.\n329: \n330: \n331: \n332: class BasicIndexer(ExplicitIndexer):\nCode replaced for brevity.\n355: \n356: \n357: \n358: class OuterIndexer(ExplicitIndexer):\nCode replaced for brevity.\n391: \n392: \n393: \n394: class VectorizedIndexer(ExplicitIndexer):\nCode replaced for brevity.\n430: \n431: \n432: \n433: class ExplicitlyIndexed:\nCode replaced for brevity.\n434: \n435: \n436: \n437: class ExplicitlyIndexedNDArrayMixin(utils.NDArrayMixin, ExplicitlyIndexed):\nCode replaced for brevity.\n441: \n442: \n443: \n444: class ImplicitToExplicitIndexingAdapter(utils.NDArrayMixin):\nCode replaced for brevity.\n462: \n463: \n464: \n465: class LazilyOuterIndexedArray(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n538: \n539: \n540: \n541: class LazilyVectorizedIndexedArray(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n588: \n589: \n590: \n591: def _wrap_numpy_scalars(array):\nCode replaced for brevity.\n596: \n597: \n598: \n599: class CopyOnWriteArray(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n620: \n621: \n622: \n623: class MemoryCachedArray(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n642: \n643: \n644: \n645: def as_indexable(array):\nCode replaced for brevity.\n659: \n660: \n661: \n662: def _outer_to_vectorized_indexer(key, shape):\nCode replaced for brevity.\n695: \n696: \n697: \n698: def _outer_to_numpy_indexer(key, shape):\nCode replaced for brevity.\n719: \n720: \n721: \n722: def _combine_indexers(old_key, shape, new_key):\nCode replaced for brevity.\n746: \n747: \n748: \n749:     # for backends that support only basic indexer\nCode replaced for brevity.\n757: \n758: \n759: \n760:         key, shape, indexing_support, raw_indexing_method):\nCode replaced for brevity.\n788: \n789: \n790: \n791: def decompose_indexer(indexer, shape, indexing_support):\nCode replaced for brevity.\n796: \n797: \n798: \n799: def _decompose_slice(key, size):\nCode replaced for brevity.\n812: \n813: \n814: \n815: def _decompose_vectorized_indexer(indexer, shape, indexing_support):\nCode replaced for brevity.\n883: \n884: \n885: \n886: def _decompose_outer_indexer(indexer, shape, indexing_support):\nCode replaced for brevity.\n1000: \n1001: \n1002: \n1003: def _arrayize_vectorized_indexer(indexer, shape):\nCode replaced for brevity.\n1021: \n1022: \n1023: \n1024: def _dask_array_with_chunks_hint(array, chunks):\nCode replaced for brevity.\n1032: \n1033: \n1034: \n1035: def _logical_any(args):\n1036:     return functools.reduce(operator.or_, args)\n1037: \n1038: \n1039: def _masked_result_drop_slice(key, chunks_hint=None):\nCode replaced for brevity.\n1045: \n1046: \n1047: \n1048: def create_mask(indexer, shape, chunks_hint=None):\nCode replaced for brevity.\n1091: \n1092: \n1093: \n1094: def _posify_mask_subindexer(index):\nCode replaced for brevity.\n1117: \n1118: \n1119: \n1120: def posify_mask_indexer(indexer):\nCode replaced for brevity.\n1140: \n1141: \n1142: \n1143: class NumpyIndexingAdapter(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n1188: \n1189: \n1190: \n1191: class DaskIndexingAdapter(ExplicitlyIndexedNDArrayMixin):\nCode replaced for brevity.\n1226: \n1227: \n1228: \n1229: class PandasIndexAdapter(ExplicitlyIndexedNDArrayMixin):\n1230:     \"\"\"Wrap a pandas.Index to preserve dtypes and handle explicit indexing.\"\"\"\n1231: \n1232:     def __init__(self, array, dtype=None):\n1233:         self.array = utils.safe_cast_to_index(array)\n1234:         if dtype is None:\n1235:             if isinstance(array, pd.PeriodIndex):\n1236:                 dtype = np.dtype('O')\n1237:             elif hasattr(array, 'categories'):\n1238:                 # category isn't a real numpy dtype\n1239:                 dtype = array.categories.dtype\n1240:             elif not utils.is_valid_numpy_dtype(array.dtype):\n1241:                 dtype = np.dtype('O')\n1242:             else:\n1243:                 dtype = array.dtype\n1244:         self._dtype = dtype\n1245: \n1246:     @property\n1247:     def dtype(self):\n1248:         return self._dtype\n1249: \n1250:     def __array__(self, dtype=None):\n1251:         if dtype is None:\n1252:             dtype = self.dtype\n1253:         array = self.array\n1254:         if isinstance(array, pd.PeriodIndex):\n1255:             with suppress(AttributeError):\n1256:                 # this might not be public API\n1257:                 array = array.astype('object')\n1258:         return np.asarray(array.values, dtype=dtype)\n1259: \n1260:     @property\n1261:     def shape(self):\n1262:         # .shape is broken on pandas prior to v0.15.2\n1263:         return (len(self.array),)\n1264: \n1265:     def __getitem__(self, indexer):\n1266:         key = indexer.tuple\n1267:         if isinstance(key, tuple) and len(key) == 1:\n1268:             # unpack key so it can index a pandas.Index object (pandas.Index\n1269:             # objects don't like tuples)\n1270:             key, = key\n1271: \n1272:         if getattr(key, 'ndim', 0) > 1:  # Return np-array if multidimensional\n1273:             return NumpyIndexingAdapter(self.array.values)[indexer]\n1274: \n1275:         result = self.array[key]\n1276: \n1277:         if isinstance(result, pd.Index):\n1278:             result = PandasIndexAdapter(result, dtype=self.dtype)\n1279:         else:\n1280:             # result is a scalar\n1281:             if result is pd.NaT:\n1282:                 # work around the impossibility of casting NaT with asarray\n1283:                 # note: it probably would be better in general to return\n1284:                 # pd.Timestamp rather np.than datetime64 but this is easier\n1285:                 # (for now)\n1286:                 result = np.datetime64('NaT', 'ns')\n1287:             elif isinstance(result, timedelta):\n1288:                 result = np.timedelta64(getattr(result, 'value', result), 'ns')\n1289:             elif isinstance(result, pd.Timestamp):\n1290:                 # Work around for GH: pydata/xarray#1932 and numpy/numpy#10668\n1291:                 # numpy fails to convert pd.Timestamp to np.datetime64[ns]\n1292:                 result = np.asarray(result.to_datetime64())\n1293:             elif self.dtype != object:\n1294:                 result = np.asarray(result, dtype=self.dtype)\n1295: \n1296:             # as for numpy.ndarray indexing, we always want the result to be\n1297:             # a NumPy array.\n1298:             result = utils.to_0d_array(result)\n1299: \n1300:         return result\n1301: \n1302:     def transpose(self, order):\n1303:         return self.array  # self.array should be always one-dimensional\n1304: \n1305:     def __repr__(self):\n1306:         return ('%s(array=%r, dtype=%r)'\n1307:                 % (type(self).__name__, self.array, self.dtype))\n\n[start of xarray/core/variable.py]\n1: import functools\n2: import itertools\n3: from collections import OrderedDict, defaultdict\n4: from datetime import timedelta\n5: from distutils.version import LooseVersion\n6: from typing import Any, Hashable, Mapping, MutableMapping, Union\n7: \n8: import numpy as np\n9: import pandas as pd\n10: \n11: import xarray as xr  # only for Dataset and DataArray\n12: \n13: from . import (\n14:     arithmetic, common, dtypes, duck_array_ops, indexing, nputils, ops, utils)\n15: from .indexing import (\n16:     BasicIndexer, OuterIndexer, PandasIndexAdapter, VectorizedIndexer,\n17:     as_indexable)\n18: from .options import _get_keep_attrs\n19: from .pycompat import dask_array_type, integer_types\n20: from .utils import (\n21:     OrderedSet, decode_numpy_dict_values, either_dict_or_kwargs,\n22:     ensure_us_time_resolution)\n23: \n24: try:\n25:     import dask.array as da\n26: except ImportError:\n27:     pass\n28: \n29: \n30: NON_NUMPY_SUPPORTED_ARRAY_TYPES = (\n31:     indexing.ExplicitlyIndexed, pd.Index) + dask_array_type\n32: # https://github.com/python/mypy/issues/224\n33: BASIC_INDEXING_TYPES = integer_types + (slice,)  # type: ignore\n34: \n35: \n36: class MissingDimensionsError(ValueError):\n37:     \"\"\"Error class used when we can't safely guess a dimension name.\n38:     \"\"\"\n39:     # inherits from ValueError for backward compatibility\n40:     # TODO: move this to an xarray.exceptions module?\n41: \n42: \n43: def as_variable(obj, name=None) -> 'Union[Variable, IndexVariable]':\n44:     \"\"\"Convert an object into a Variable.\n45: \n46:     Parameters\n47:     ----------\n48:     obj : object\n49:         Object to convert into a Variable.\n50: \n51:         - If the object is already a Variable, return a shallow copy.\n52:         - Otherwise, if the object has 'dims' and 'data' attributes, convert\n53:           it into a new Variable.\n54:         - If all else fails, attempt to convert the object into a Variable by\n55:           unpacking it into the arguments for creating a new Variable.\n56:     name : str, optional\n57:         If provided:\n58: \n59:         - `obj` can be a 1D array, which is assumed to label coordinate values\n60:           along a dimension of this given name.\n61:         - Variables with name matching one of their dimensions are converted\n62:           into `IndexVariable` objects.\n63: \n64:     Returns\n65:     -------\n66:     var : Variable\n67:         The newly created variable.\n68: \n69:     \"\"\"\n70:     from .dataarray import DataArray\n71: \n72:     # TODO: consider extending this method to automatically handle Iris and\n73:     if isinstance(obj, DataArray):\n74:         # extract the primary Variable from DataArrays\n75:         obj = obj.variable\n76: \n77:     if isinstance(obj, Variable):\n78:         obj = obj.copy(deep=False)\n79:     elif isinstance(obj, tuple):\n80:         try:\n81:             obj = Variable(*obj)\n82:         except (TypeError, ValueError) as error:\n83:             # use .format() instead of % because it handles tuples consistently\n84:             raise error.__class__('Could not convert tuple of form '\n85:                                   '(dims, data[, attrs, encoding]): '\n86:                                   '{} to Variable.'.format(obj))\n87:     elif utils.is_scalar(obj):\n88:         obj = Variable([], obj)\n89:     elif isinstance(obj, (pd.Index, IndexVariable)) and obj.name is not None:\n90:         obj = Variable(obj.name, obj)\n91:     elif isinstance(obj, (set, dict)):\n92:         raise TypeError(\n93:             \"variable %r has invalid type %r\" % (name, type(obj)))\n94:     elif name is not None:\n95:         data = as_compatible_data(obj)\n96:         if data.ndim != 1:\n97:             raise MissingDimensionsError(\n98:                 'cannot set variable %r with %r-dimensional data '\n99:                 'without explicit dimension names. Pass a tuple of '\n100:                 '(dims, data) instead.' % (name, data.ndim))\n101:         obj = Variable(name, data, fastpath=True)\n102:     else:\n103:         raise TypeError('unable to convert object into a variable without an '\n104:                         'explicit list of dimensions: %r' % obj)\n105: \n106:     if name is not None and name in obj.dims:\n107:         # convert the Variable into an Index\n108:         if obj.ndim != 1:\n109:             raise MissingDimensionsError(\n110:                 '%r has more than 1-dimension and the same name as one of its '\n111:                 'dimensions %r. xarray disallows such variables because they '\n112:                 'conflict with the coordinates used to label '\n113:                 'dimensions.' % (name, obj.dims))\n114:         obj = obj.to_index_variable()\n115: \n116:     return obj\n117: \n118: \n119: def _maybe_wrap_data(data):\nCode replaced for brevity.\n129: \n130: \n131: \n132: def _possibly_convert_objects(values):\nCode replaced for brevity.\n136: \n137: \n138: \n139: def as_compatible_data(data, fastpath=False):\nCode replaced for brevity.\n193: \n194: \n195: \n196: def _as_array_or_item(data):\nCode replaced for brevity.\n216: \n217: \n218: \n219:                utils.NdimSizeLenMixin):\nCode replaced for brevity.\n1828: \n1829: \n1830: \n1831: ops.inject_all_ops_and_reduce_methods(Variable)\n1832: \n1833: \n1834: class IndexVariable(Variable):\n1835:     \"\"\"Wrapper for accommodating a pandas.Index in an xarray.Variable.\n1836: \n1837:     IndexVariable preserve loaded values in the form of a pandas.Index instead\n1838:     of a NumPy array. Hence, their values are immutable and must always be one-\n1839:     dimensional.\n1840: \n1841:     They also have a name property, which is the name of their sole dimension\n1842:     unless another name is given.\n1843:     \"\"\"\n1844: \n1845:     def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n1846:         super().__init__(dims, data, attrs, encoding, fastpath)\n1847:         if self.ndim != 1:\n1848:             raise ValueError('%s objects must be 1-dimensional' %\n1849:                              type(self).__name__)\n1850: \n1851:         # Unlike in Variable, always eagerly load values into memory\n1852:         if not isinstance(self._data, PandasIndexAdapter):\n1853:             self._data = PandasIndexAdapter(self._data)\n1854: \n1855:     def load(self):\n1856:         # data is already loaded into memory for IndexVariable\n1857:         return self\n1858: \n1859:     # https://github.com/python/mypy/issues/1465\n1860:     @Variable.data.setter  # type: ignore\n1861:     def data(self, data):\n1862:         Variable.data.fset(self, data)\n1863:         if not isinstance(self._data, PandasIndexAdapter):\n1864:             self._data = PandasIndexAdapter(self._data)\n1865: \n1866:     def chunk(self, chunks=None, name=None, lock=False):\n1867:         # Dummy - do not chunk. This method is invoked e.g. by Dataset.chunk()\n1868:         return self.copy(deep=False)\n1869: \n1870:     def _finalize_indexing_result(self, dims, data):\n1871:         if getattr(data, 'ndim', 0) != 1:\n1872:             # returns Variable rather than IndexVariable if multi-dimensional\n1873:             return Variable(dims, data, self._attrs, self._encoding)\n1874:         else:\n1875:             return type(self)(dims, data, self._attrs,\n1876:                               self._encoding, fastpath=True)\n1877: \n1878:     def __setitem__(self, key, value):\n1879:         raise TypeError('%s values cannot be modified' % type(self).__name__)\n1880: \n1881:     @classmethod\n1882:     def concat(cls, variables, dim='concat_dim', positions=None,\n1883:                shortcut=False):\n1884:         \"\"\"Specialized version of Variable.concat for IndexVariable objects.\n1885: \n1886:         This exists because we want to avoid converting Index objects to NumPy\n1887:         arrays, if possible.\n1888:         \"\"\"\n1889:         if not isinstance(dim, str):\n1890:             dim, = dim.dims\n1891: \n1892:         variables = list(variables)\n1893:         first_var = variables[0]\n1894: \n1895:         if any(not isinstance(v, cls) for v in variables):\n1896:             raise TypeError('IndexVariable.concat requires that all input '\n1897:                             'variables be IndexVariable objects')\n1898: \n1899:         indexes = [v._data.array for v in variables]\n1900: \n1901:         if not indexes:\n1902:             data = []\n1903:         else:\n1904:             data = indexes[0].append(indexes[1:])\n1905: \n1906:             if positions is not None:\n1907:                 indices = nputils.inverse_permutation(\n1908:                     np.concatenate(positions))\n1909:                 data = data.take(indices)\n1910: \n1911:         attrs = OrderedDict(first_var.attrs)\n1912:         if not shortcut:\n1913:             for var in variables:\n1914:                 if var.dims != first_var.dims:\n1915:                     raise ValueError('inconsistent dimensions')\n1916:                 utils.remove_incompatible_items(attrs, var.attrs)\n1917: \n1918:         return cls(first_var.dims, data, attrs)\n1919: \n1920:     def copy(self, deep=True, data=None):\n1921:         \"\"\"Returns a copy of this object.\n1922: \n1923:         `deep` is ignored since data is stored in the form of\n1924:         pandas.Index, which is already immutable. Dimensions, attributes\n1925:         and encodings are always copied.\n1926: \n1927:         Use `data` to create a new object with the same structure as\n1928:         original but entirely new data.\n1929: \n1930:         Parameters\n1931:         ----------\n1932:         deep : bool, optional\n1933:             Deep is ignored when data is given. Whether the data array is\n1934:             loaded into memory and copied onto the new object. Default is True.\n1935:         data : array_like, optional\n1936:             Data to use in the new object. Must have same shape as original.\n1937: \n1938:         Returns\n1939:         -------\n1940:         object : Variable\n1941:             New object with dimensions, attributes, encodings, and optionally\n1942:             data copied from original.\n1943:         \"\"\"\n1944:         if data is None:\n1945:             if deep:\n1946:                 # self._data should be a `PandasIndexAdapter` instance at this\n1947:                 # point, which doesn't have a copy method, so make a deep copy\n1948:                 # of the underlying `pandas.MultiIndex` and create a new\n1949:                 # `PandasIndexAdapter` instance with it.\n1950:                 data = PandasIndexAdapter(self._data.array.copy(deep=True))\n1951:             else:\n1952:                 data = self._data\n1953:         else:\n1954:             data = as_compatible_data(data)\n1955:             if self.shape != data.shape:\n1956:                 raise ValueError(\"Data shape {} must match shape of object {}\"\n1957:                                  .format(data.shape, self.shape))\n1958:         return type(self)(self.dims, data, self._attrs,\n1959:                           self._encoding, fastpath=True)\n1960: \n1961:     def equals(self, other, equiv=None):\n1962:         # if equiv is specified, super up\n1963:         if equiv is not None:\n1964:             return super().equals(other, equiv)\n1965: \n1966:         # otherwise use the native index equals, rather than looking at _data\n1967:         other = getattr(other, 'variable', other)\n1968:         try:\n1969:             return (self.dims == other.dims and\n1970:                     self._data_equals(other))\n1971:         except (TypeError, AttributeError):\n1972:             return False\n1973: \n1974:     def _data_equals(self, other):\n1975:         return self.to_index().equals(other.to_index())\n1976: \n1977:     def to_index_variable(self):\n1978:         \"\"\"Return this variable as an xarray.IndexVariable\"\"\"\n1979:         return self\n1980: \n1981:     to_coord = utils.alias(to_index_variable, 'to_coord')\n1982: \n1983:     def to_index(self):\n1984:         \"\"\"Convert this variable to a pandas.Index\"\"\"\n1985:         # n.b. creating a new pandas.Index from an old pandas.Index is\n1986:         # basically free as pandas.Index objects are immutable\n1987:         assert self.ndim == 1\n1988:         index = self._data.array\n1989:         if isinstance(index, pd.MultiIndex):\n1990:             # set default names for multi-index unnamed levels so that\n1991:             # we can safely rename dimension / coordinate later\n1992:             valid_level_names = [name or '{}_level_{}'.format(self.dims[0], i)\n1993:                                  for i, name in enumerate(index.names)]\n1994:             index = index.set_names(valid_level_names)\n1995:         else:\n1996:             index = index.set_names(self.name)\n1997:         return index\n1998: \n1999:     @property\n2000:     def level_names(self):\n2001:         \"\"\"Return MultiIndex level names or None if this IndexVariable has no\n2002:         MultiIndex.\n2003:         \"\"\"\n2004:         index = self.to_index()\n2005:         if isinstance(index, pd.MultiIndex):\n2006:             return index.names\n2007:         else:\n2008:             return None\n2009: \n2010:     def get_level_variable(self, level):\n2011:         \"\"\"Return a new IndexVariable from a given MultiIndex level.\"\"\"\n2012:         if self.level_names is None:\n2013:             raise ValueError(\"IndexVariable %r has no MultiIndex\" % self.name)\n2014:         index = self.to_index()\n2015:         return type(self)(self.dims, index.get_level_values(level))\n2016: \n2017:     @property\n2018:     def name(self):\n2019:         return self.dims[0]\n2020: \n2021:     @name.setter\n2022:     def name(self, value):\n2023:         raise AttributeError('cannot modify name of IndexVariable in-place')\n2024: \n2025: \n2026: # for backwards compatibility\n2027: Coordinate = utils.alias(IndexVariable, 'Coordinate')\n2028: \n2029: \n2030:     # validate dimensions\nCode replaced for brevity.\n2045: \n2046: \n2047: \n2048: def _broadcast_compat_variables(*variables):\nCode replaced for brevity.\n2056: \n2057: \n2058: \n2059: def broadcast_variables(*variables):\nCode replaced for brevity.\n2072: \n2073: \n2074: \n2075: def _broadcast_compat_data(self, other):\nCode replaced for brevity.\n2088: \n2089: \n2090: \n2091: def concat(variables, dim='concat_dim', positions=None, shortcut=False):\nCode replaced for brevity.\n2125: \n2126: \n2127: \n2128: def assert_unique_multiindex_level_names(variables):\nCode replaced for brevity.\n2160: \n\n",
  "line_level_localization": [
    {
      "filename": "/xarray/core/indexing.py",
      "suspect_lines": [
        6,
        1230,
        1232,
        1247,
        1250,
        1261,
        1265,
        1302,
        1305
      ]
    },
    {
      "filename": "/xarray/core/variable.py",
      "suspect_lines": [
        1945,
        1946,
        1947,
        1948,
        1949,
        1950,
        1951,
        1952
      ]
    }
  ]
}