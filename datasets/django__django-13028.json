{
  "instance_id": "django__django-13028",
  "problem_statement": "Queryset raises NotSupportedError when RHS has filterable=False attribute.\nDescription\n\t \n\t\t(last modified by Nicolas Baccelli)\n\t \nI'm migrating my app to django 3.0.7 and I hit a strange behavior using a model class with a field labeled filterable\nclass ProductMetaDataType(models.Model):\n\tlabel = models.CharField(max_length=255, unique=True, blank=False, null=False)\n\tfilterable = models.BooleanField(default=False, verbose_name=_(\"filterable\"))\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose_name = _(\"product meta data type\")\n\t\tverbose_name_plural = _(\"product meta data types\")\n\tdef __str__(self):\n\t\treturn self.label\nclass ProductMetaData(models.Model):\n\tid = models.BigAutoField(primary_key=True)\n\tproduct = models.ForeignKey(\n\t\tProduit, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tvalue = models.TextField(null=False, blank=False)\n\tmarketplace = models.ForeignKey(\n\t\tPlateforme, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tdate_created = models.DateTimeField(null=True, default=timezone.now)\n\tmetadata_type = models.ForeignKey(\n\t\tProductMetaDataType, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose_name = _(\"product meta data\")\n\t\tverbose_name_plural = _(\"product meta datas\")\nError happened when filtering ProductMetaData with a metadata_type :\nProductMetaData.objects.filter(value=\"Dark Vador\", metadata_type=self.brand_metadata)\nError traceback :\nTraceback (most recent call last):\n File \"/backoffice/backoffice/adminpricing/tests/test_pw.py\", line 481, in test_checkpolicywarning_by_fields\n\tfor p in ProductMetaData.objects.filter(\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/manager.py\", line 82, in manager_method\n\treturn getattr(self.get_queryset(), name)(*args, **kwargs)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/query.py\", line 904, in filter\n\treturn self._filter_or_exclude(False, *args, **kwargs)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/query.py\", line 923, in _filter_or_exclude\n\tclone.query.add_q(Q(*args, **kwargs))\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1351, in add_q\n\tclause, _ = self._add_q(q_object, self.used_aliases)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1378, in _add_q\n\tchild_clause, needed_inner = self.build_filter(\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1264, in build_filter\n\tself.check_filterable(value)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1131, in check_filterable\n\traise NotSupportedError(\ndjango.db.utils.NotSupportedError: ProductMetaDataType is disallowed in the filter clause.\nI changed label to filterable_test and it fixed this issue\nThis should be documented or fix.\n",
  "localized_code": "[start of django/db/models/sql/query.py]\n1: \"\"\"\n2: Create SQL statements for QuerySets.\n3: \n4: The code in here encapsulates all of the SQL construction so that QuerySets\n5: themselves do not have to (and could be backed by things other than SQL\n6: databases). The abstraction barrier only works one way: this module has to know\n7: all about the internals of models in order to get the information it needs.\n8: \"\"\"\n9: import copy\n10: import difflib\n11: import functools\n12: import inspect\n13: import sys\n14: import warnings\n15: from collections import Counter, namedtuple\n16: from collections.abc import Iterator, Mapping\n17: from itertools import chain, count, product\n18: from string import ascii_uppercase\n19: \n20: from django.core.exceptions import (\n21:     EmptyResultSet, FieldDoesNotExist, FieldError,\n22: )\n23: from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n24: from django.db.models.aggregates import Count\n25: from django.db.models.constants import LOOKUP_SEP\n26: from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref\n27: from django.db.models.fields import Field\n28: from django.db.models.fields.related_lookups import MultiColSource\n29: from django.db.models.lookups import Lookup\n30: from django.db.models.query_utils import (\n31:     Q, check_rel_lookup_compatibility, refs_expression,\n32: )\n33: from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE\n34: from django.db.models.sql.datastructures import (\n35:     BaseTable, Empty, Join, MultiJoin,\n36: )\n37: from django.db.models.sql.where import (\n38:     AND, OR, ExtraWhere, NothingNode, WhereNode,\n39: )\n40: from django.utils.deprecation import RemovedInDjango40Warning\n41: from django.utils.functional import cached_property\n42: from django.utils.tree import Node\n43: \n44: __all__ = ['Query', 'RawQuery']\n45: \n46: \n47: def get_field_names_from_opts(opts):\n48:     return set(chain.from_iterable(\n49:         (f.name, f.attname) if f.concrete else (f.name,)\n50:         for f in opts.get_fields()\n51:     ))\n52: \n53: \n54: def get_children_from_q(q):\nCode replaced for brevity.\n59: \n60: \n61: \n62: JoinInfo = namedtuple(\n63:     'JoinInfo',\n64:     ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')\n65: )\n66: \n67: \n68: class RawQuery:\nCode replaced for brevity.\n133: \n134: \n135: \n136: class Query(BaseExpression):\n137:     \"\"\"A single SQL query.\"\"\"\n138: \n139:     alias_prefix = 'T'\n140:     subq_aliases = frozenset([alias_prefix])\n141: \n142:     compiler = 'SQLCompiler'\n143: \n144:     def __init__(self, model, where=WhereNode, alias_cols=True):\n145:         self.model = model\n146:         self.alias_refcount = {}\n147:         # alias_map is the most important data structure regarding joins.\n148:         # It's used for recording which joins exist in the query and what\n149:         # types they are. The key is the alias of the joined table (possibly\n150:         # the table name) and the value is a Join-like object (see\n151:         # sql.datastructures.Join for more information).\n152:         self.alias_map = {}\n153:         # Whether to provide alias to columns during reference resolving.\n154:         self.alias_cols = alias_cols\n155:         # Sometimes the query contains references to aliases in outer queries (as\n156:         # a result of split_exclude). Correct alias quoting needs to know these\n157:         # aliases too.\n158:         # Map external tables to whether they are aliased.\n159:         self.external_aliases = {}\n160:         self.table_map = {}     # Maps table names to list of aliases.\n161:         self.default_cols = True\n162:         self.default_ordering = True\n163:         self.standard_ordering = True\n164:         self.used_aliases = set()\n165:         self.filter_is_sticky = False\n166:         self.subquery = False\n167: \n168:         # SQL-related attributes\n169:         # Select and related select clauses are expressions to use in the\n170:         # SELECT clause of the query.\n171:         # The select is used for cases where we want to set up the select\n172:         # clause to contain other than default fields (values(), subqueries...)\n173:         # Note that annotations go to annotations dictionary.\n174:         self.select = ()\n175:         self.where = where()\n176:         self.where_class = where\n177:         # The group_by attribute can have one of the following forms:\n178:         #  - None: no group by at all in the query\n179:         #  - A tuple of expressions: group by (at least) those expressions.\n180:         #    String refs are also allowed for now.\n181:         #  - True: group by all select fields of the model\n182:         # See compiler.get_group_by() for details.\n183:         self.group_by = None\n184:         self.order_by = ()\n185:         self.low_mark, self.high_mark = 0, None  # Used for offset/limit\n186:         self.distinct = False\n187:         self.distinct_fields = ()\n188:         self.select_for_update = False\n189:         self.select_for_update_nowait = False\n190:         self.select_for_update_skip_locked = False\n191:         self.select_for_update_of = ()\n192:         self.select_for_no_key_update = False\n193: \n194:         self.select_related = False\n195:         # Arbitrary limit for select_related to prevents infinite recursion.\n196:         self.max_depth = 5\n197: \n198:         # Holds the selects defined by a call to values() or values_list()\n199:         # excluding annotation_select and extra_select.\n200:         self.values_select = ()\n201: \n202:         # SQL annotation-related attributes\n203:         self.annotations = {}  # Maps alias -> Annotation Expression\n204:         self.annotation_select_mask = None\n205:         self._annotation_select_cache = None\n206: \n207:         # Set combination attributes\n208:         self.combinator = None\n209:         self.combinator_all = False\n210:         self.combined_queries = ()\n211: \n212:         # These are for extensions. The contents are more or less appended\n213:         # verbatim to the appropriate clause.\n214:         self.extra = {}  # Maps col_alias -> (col_sql, params).\n215:         self.extra_select_mask = None\n216:         self._extra_select_cache = None\n217: \n218:         self.extra_tables = ()\n219:         self.extra_order_by = ()\n220: \n221:         # A tuple that is a set of model field names and either True, if these\n222:         # are the fields to defer, or False if these are the only fields to\n223:         # load.\n224:         self.deferred_loading = (frozenset(), True)\n225: \n226:         self._filtered_relations = {}\n227: \n228:         self.explain_query = False\n229:         self.explain_format = None\n230:         self.explain_options = {}\n231: \n232:     @property\n233:     def output_field(self):\n234:         if len(self.select) == 1:\n235:             select = self.select[0]\n236:             return getattr(select, 'target', None) or select.field\n237:         elif len(self.annotation_select) == 1:\n238:             return next(iter(self.annotation_select.values())).output_field\n239: \n240:     @property\n241:     def has_select_fields(self):\n242:         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)\n243: \n244:     @cached_property\n245:     def base_table(self):\n246:         for alias in self.alias_map:\n247:             return alias\n248: \n249:     def __str__(self):\n250:         \"\"\"\n251:         Return the query as a string of SQL with the parameter values\n252:         substituted in (use sql_with_params() to see the unsubstituted string).\n253: \n254:         Parameter values won't necessarily be quoted correctly, since that is\n255:         done by the database interface at execution time.\n256:         \"\"\"\n257:         sql, params = self.sql_with_params()\n258:         return sql % params\n259: \n260:     def sql_with_params(self):\n261:         \"\"\"\n262:         Return the query as an SQL string and the parameters that will be\n263:         substituted into the query.\n264:         \"\"\"\n265:         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()\n266: \n267:     def __deepcopy__(self, memo):\n268:         \"\"\"Limit the amount of work when a Query is deepcopied.\"\"\"\n269:         result = self.clone()\n270:         memo[id(self)] = result\n271:         return result\n272: \n273:     def get_compiler(self, using=None, connection=None):\n274:         if using is None and connection is None:\n275:             raise ValueError(\"Need either using or connection\")\n276:         if using:\n277:             connection = connections[using]\n278:         return connection.ops.compiler(self.compiler)(self, connection, using)\n279: \n280:     def get_meta(self):\n281:         \"\"\"\n282:         Return the Options instance (the model._meta) from which to start\n283:         processing. Normally, this is self.model._meta, but it can be changed\n284:         by subclasses.\n285:         \"\"\"\n286:         return self.model._meta\n287: \n288:     def clone(self):\n289:         \"\"\"\n290:         Return a copy of the current Query. A lightweight alternative to\n291:         to deepcopy().\n292:         \"\"\"\n293:         obj = Empty()\n294:         obj.__class__ = self.__class__\n295:         # Copy references to everything.\n296:         obj.__dict__ = self.__dict__.copy()\n297:         # Clone attributes that can't use shallow copy.\n298:         obj.alias_refcount = self.alias_refcount.copy()\n299:         obj.alias_map = self.alias_map.copy()\n300:         obj.external_aliases = self.external_aliases.copy()\n301:         obj.table_map = self.table_map.copy()\n302:         obj.where = self.where.clone()\n303:         obj.annotations = self.annotations.copy()\n304:         if self.annotation_select_mask is None:\n305:             obj.annotation_select_mask = None\n306:         else:\n307:             obj.annotation_select_mask = self.annotation_select_mask.copy()\n308:         # _annotation_select_cache cannot be copied, as doing so breaks the\n309:         # (necessary) state in which both annotations and\n310:         # _annotation_select_cache point to the same underlying objects.\n311:         # It will get re-populated in the cloned queryset the next time it's\n312:         # used.\n313:         obj._annotation_select_cache = None\n314:         obj.extra = self.extra.copy()\n315:         if self.extra_select_mask is None:\n316:             obj.extra_select_mask = None\n317:         else:\n318:             obj.extra_select_mask = self.extra_select_mask.copy()\n319:         if self._extra_select_cache is None:\n320:             obj._extra_select_cache = None\n321:         else:\n322:             obj._extra_select_cache = self._extra_select_cache.copy()\n323:         if self.select_related is not False:\n324:             # Use deepcopy because select_related stores fields in nested\n325:             # dicts.\n326:             obj.select_related = copy.deepcopy(obj.select_related)\n327:         if 'subq_aliases' in self.__dict__:\n328:             obj.subq_aliases = self.subq_aliases.copy()\n329:         obj.used_aliases = self.used_aliases.copy()\n330:         obj._filtered_relations = self._filtered_relations.copy()\n331:         # Clear the cached_property\n332:         try:\n333:             del obj.base_table\n334:         except AttributeError:\n335:             pass\n336:         return obj\n337: \n338:     def chain(self, klass=None):\n339:         \"\"\"\n340:         Return a copy of the current Query that's ready for another operation.\n341:         The klass argument changes the type of the Query, e.g. UpdateQuery.\n342:         \"\"\"\n343:         obj = self.clone()\n344:         if klass and obj.__class__ != klass:\n345:             obj.__class__ = klass\n346:         if not obj.filter_is_sticky:\n347:             obj.used_aliases = set()\n348:         obj.filter_is_sticky = False\n349:         if hasattr(obj, '_setup_query'):\n350:             obj._setup_query()\n351:         return obj\n352: \n353:     def relabeled_clone(self, change_map):\n354:         clone = self.clone()\n355:         clone.change_aliases(change_map)\n356:         return clone\n357: \n358:     def _get_col(self, target, field, alias):\n359:         if not self.alias_cols:\n360:             alias = None\n361:         return target.get_col(alias, field)\n362: \n363:     def rewrite_cols(self, annotation, col_cnt):\n364:         # We must make sure the inner query has the referred columns in it.\n365:         # If we are aggregating over an annotation, then Django uses Ref()\n366:         # instances to note this. However, if we are annotating over a column\n367:         # of a related model, then it might be that column isn't part of the\n368:         # SELECT clause of the inner query, and we must manually make sure\n369:         # the column is selected. An example case is:\n370:         #    .aggregate(Sum('author__awards'))\n371:         # Resolving this expression results in a join to author, but there\n372:         # is no guarantee the awards column of author is in the select clause\n373:         # of the query. Thus we must manually add the column to the inner\n374:         # query.\n375:         orig_exprs = annotation.get_source_expressions()\n376:         new_exprs = []\n377:         for expr in orig_exprs:\n378:             # FIXME: These conditions are fairly arbitrary. Identify a better\n379:             # method of having expressions decide which code path they should\n380:             # take.\n381:             if isinstance(expr, Ref):\n382:                 # Its already a Ref to subquery (see resolve_ref() for\n383:                 # details)\n384:                 new_exprs.append(expr)\n385:             elif isinstance(expr, (WhereNode, Lookup)):\n386:                 # Decompose the subexpressions further. The code here is\n387:                 # copied from the else clause, but this condition must appear\n388:                 # before the contains_aggregate/is_summary condition below.\n389:                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n390:                 new_exprs.append(new_expr)\n391:             else:\n392:                 # Reuse aliases of expressions already selected in subquery.\n393:                 for col_alias, selected_annotation in self.annotation_select.items():\n394:                     if selected_annotation is expr:\n395:                         new_expr = Ref(col_alias, expr)\n396:                         break\n397:                 else:\n398:                     # An expression that is not selected the subquery.\n399:                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):\n400:                         # Reference column or another aggregate. Select it\n401:                         # under a non-conflicting alias.\n402:                         col_cnt += 1\n403:                         col_alias = '__col%d' % col_cnt\n404:                         self.annotations[col_alias] = expr\n405:                         self.append_annotation_mask([col_alias])\n406:                         new_expr = Ref(col_alias, expr)\n407:                     else:\n408:                         # Some other expression not referencing database values\n409:                         # directly. Its subexpression might contain Cols.\n410:                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)\n411:                 new_exprs.append(new_expr)\n412:         annotation.set_source_expressions(new_exprs)\n413:         return annotation, col_cnt\n414: \n415:     def get_aggregation(self, using, added_aggregate_names):\n416:         \"\"\"\n417:         Return the dictionary with the values of the existing aggregations.\n418:         \"\"\"\n419:         if not self.annotation_select:\n420:             return {}\n421:         existing_annotations = [\n422:             annotation for alias, annotation\n423:             in self.annotations.items()\n424:             if alias not in added_aggregate_names\n425:         ]\n426:         # Decide if we need to use a subquery.\n427:         #\n428:         # Existing annotations would cause incorrect results as get_aggregation()\n429:         # must produce just one result and thus must not use GROUP BY. But we\n430:         # aren't smart enough to remove the existing annotations from the\n431:         # query, so those would force us to use GROUP BY.\n432:         #\n433:         # If the query has limit or distinct, or uses set operations, then\n434:         # those operations must be done in a subquery so that the query\n435:         # aggregates on the limit and/or distinct results instead of applying\n436:         # the distinct and limit after the aggregation.\n437:         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or\n438:                 self.distinct or self.combinator):\n439:             from django.db.models.sql.subqueries import AggregateQuery\n440:             outer_query = AggregateQuery(self.model)\n441:             inner_query = self.clone()\n442:             inner_query.select_for_update = False\n443:             inner_query.select_related = False\n444:             inner_query.set_annotation_mask(self.annotation_select)\n445:             if not self.is_sliced and not self.distinct_fields:\n446:                 # Queries with distinct_fields need ordering and when a limit\n447:                 # is applied we must take the slice from the ordered query.\n448:                 # Otherwise no need for ordering.\n449:                 inner_query.clear_ordering(True)\n450:             if not inner_query.distinct:\n451:                 # If the inner query uses default select and it has some\n452:                 # aggregate annotations, then we must make sure the inner\n453:                 # query is grouped by the main model's primary key. However,\n454:                 # clearing the select clause can alter results if distinct is\n455:                 # used.\n456:                 has_existing_aggregate_annotations = any(\n457:                     annotation for annotation in existing_annotations\n458:                     if getattr(annotation, 'contains_aggregate', True)\n459:                 )\n460:                 if inner_query.default_cols and has_existing_aggregate_annotations:\n461:                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n462:                 inner_query.default_cols = False\n463: \n464:             relabels = {t: 'subquery' for t in inner_query.alias_map}\n465:             relabels[None] = 'subquery'\n466:             # Remove any aggregates marked for reduction from the subquery\n467:             # and move them to the outer AggregateQuery.\n468:             col_cnt = 0\n469:             for alias, expression in list(inner_query.annotation_select.items()):\n470:                 annotation_select_mask = inner_query.annotation_select_mask\n471:                 if expression.is_summary:\n472:                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)\n473:                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)\n474:                     del inner_query.annotations[alias]\n475:                     annotation_select_mask.remove(alias)\n476:                 # Make sure the annotation_select wont use cached results.\n477:                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)\n478:             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:\n479:                 # In case of Model.objects[0:3].count(), there would be no\n480:                 # field selected in the inner query, yet we must use a subquery.\n481:                 # So, make sure at least one field is selected.\n482:                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n483:             try:\n484:                 outer_query.add_subquery(inner_query, using)\n485:             except EmptyResultSet:\n486:                 return {\n487:                     alias: None\n488:                     for alias in outer_query.annotation_select\n489:                 }\n490:         else:\n491:             outer_query = self\n492:             self.select = ()\n493:             self.default_cols = False\n494:             self.extra = {}\n495: \n496:         outer_query.clear_ordering(True)\n497:         outer_query.clear_limits()\n498:         outer_query.select_for_update = False\n499:         outer_query.select_related = False\n500:         compiler = outer_query.get_compiler(using)\n501:         result = compiler.execute_sql(SINGLE)\n502:         if result is None:\n503:             result = [None] * len(outer_query.annotation_select)\n504: \n505:         converters = compiler.get_converters(outer_query.annotation_select.values())\n506:         result = next(compiler.apply_converters((result,), converters))\n507: \n508:         return dict(zip(outer_query.annotation_select, result))\n509: \n510:     def get_count(self, using):\n511:         \"\"\"\n512:         Perform a COUNT() query using the current filter constraints.\n513:         \"\"\"\n514:         obj = self.clone()\n515:         obj.add_annotation(Count('*'), alias='__count', is_summary=True)\n516:         number = obj.get_aggregation(using, ['__count'])['__count']\n517:         if number is None:\n518:             number = 0\n519:         return number\n520: \n521:     def has_filters(self):\n522:         return self.where\n523: \n524:     def has_results(self, using):\n525:         q = self.clone()\n526:         if not q.distinct:\n527:             if q.group_by is True:\n528:                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)\n529:                 # Disable GROUP BY aliases to avoid orphaning references to the\n530:                 # SELECT clause which is about to be cleared.\n531:                 q.set_group_by(allow_aliases=False)\n532:             q.clear_select_clause()\n533:         q.clear_ordering(True)\n534:         q.set_limits(high=1)\n535:         compiler = q.get_compiler(using=using)\n536:         return compiler.has_results()\n537: \n538:     def explain(self, using, format=None, **options):\n539:         q = self.clone()\n540:         q.explain_query = True\n541:         q.explain_format = format\n542:         q.explain_options = options\n543:         compiler = q.get_compiler(using=using)\n544:         return '\\n'.join(compiler.explain_query())\n545: \n546:     def combine(self, rhs, connector):\n547:         \"\"\"\n548:         Merge the 'rhs' query into the current one (with any 'rhs' effects\n549:         being applied *after* (that is, \"to the right of\") anything in the\n550:         current query. 'rhs' is not modified during a call to this function.\n551: \n552:         The 'connector' parameter describes how to connect filters from the\n553:         'rhs' query.\n554:         \"\"\"\n555:         assert self.model == rhs.model, \\\n556:             \"Cannot combine queries on two different base models.\"\n557:         assert not self.is_sliced, \\\n558:             \"Cannot combine queries once a slice has been taken.\"\n559:         assert self.distinct == rhs.distinct, \\\n560:             \"Cannot combine a unique query with a non-unique query.\"\n561:         assert self.distinct_fields == rhs.distinct_fields, \\\n562:             \"Cannot combine queries with different distinct fields.\"\n563: \n564:         # Work out how to relabel the rhs aliases, if necessary.\n565:         change_map = {}\n566:         conjunction = (connector == AND)\n567: \n568:         # Determine which existing joins can be reused. When combining the\n569:         # query with AND we must recreate all joins for m2m filters. When\n570:         # combining with OR we can reuse joins. The reason is that in AND\n571:         # case a single row can't fulfill a condition like:\n572:         #     revrel__col=1 & revrel__col=2\n573:         # But, there might be two different related rows matching this\n574:         # condition. In OR case a single True is enough, so single row is\n575:         # enough, too.\n576:         #\n577:         # Note that we will be creating duplicate joins for non-m2m joins in\n578:         # the AND case. The results will be correct but this creates too many\n579:         # joins. This is something that could be fixed later on.\n580:         reuse = set() if conjunction else set(self.alias_map)\n581:         # Base table must be present in the query - this is the same\n582:         # table on both sides.\n583:         self.get_initial_alias()\n584:         joinpromoter = JoinPromoter(connector, 2, False)\n585:         joinpromoter.add_votes(\n586:             j for j in self.alias_map if self.alias_map[j].join_type == INNER)\n587:         rhs_votes = set()\n588:         # Now, add the joins from rhs query into the new query (skipping base\n589:         # table).\n590:         rhs_tables = list(rhs.alias_map)[1:]\n591:         for alias in rhs_tables:\n592:             join = rhs.alias_map[alias]\n593:             # If the left side of the join was already relabeled, use the\n594:             # updated alias.\n595:             join = join.relabeled_clone(change_map)\n596:             new_alias = self.join(join, reuse=reuse)\n597:             if join.join_type == INNER:\n598:                 rhs_votes.add(new_alias)\n599:             # We can't reuse the same join again in the query. If we have two\n600:             # distinct joins for the same connection in rhs query, then the\n601:             # combined query must have two joins, too.\n602:             reuse.discard(new_alias)\n603:             if alias != new_alias:\n604:                 change_map[alias] = new_alias\n605:             if not rhs.alias_refcount[alias]:\n606:                 # The alias was unused in the rhs query. Unref it so that it\n607:                 # will be unused in the new query, too. We have to add and\n608:                 # unref the alias so that join promotion has information of\n609:                 # the join type for the unused alias.\n610:                 self.unref_alias(new_alias)\n611:         joinpromoter.add_votes(rhs_votes)\n612:         joinpromoter.update_join_types(self)\n613: \n614:         # Now relabel a copy of the rhs where-clause and add it to the current\n615:         # one.\n616:         w = rhs.where.clone()\n617:         w.relabel_aliases(change_map)\n618:         self.where.add(w, connector)\n619: \n620:         # Selection columns and extra extensions are those provided by 'rhs'.\n621:         if rhs.select:\n622:             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])\n623:         else:\n624:             self.select = ()\n625: \n626:         if connector == OR:\n627:             # It would be nice to be able to handle this, but the queries don't\n628:             # really make sense (or return consistent value sets). Not worth\n629:             # the extra complexity when you can write a real query instead.\n630:             if self.extra and rhs.extra:\n631:                 raise ValueError(\"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\")\n632:         self.extra.update(rhs.extra)\n633:         extra_select_mask = set()\n634:         if self.extra_select_mask is not None:\n635:             extra_select_mask.update(self.extra_select_mask)\n636:         if rhs.extra_select_mask is not None:\n637:             extra_select_mask.update(rhs.extra_select_mask)\n638:         if extra_select_mask:\n639:             self.set_extra_mask(extra_select_mask)\n640:         self.extra_tables += rhs.extra_tables\n641: \n642:         # Ordering uses the 'rhs' ordering, unless it has none, in which case\n643:         # the current ordering is used.\n644:         self.order_by = rhs.order_by or self.order_by\n645:         self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n646: \n647:     def deferred_to_data(self, target, callback):\n648:         \"\"\"\n649:         Convert the self.deferred_loading data structure to an alternate data\n650:         structure, describing the field that *will* be loaded. This is used to\n651:         compute the columns to select from the database and also by the\n652:         QuerySet class to work out which fields are being initialized on each\n653:         model. Models that have all their fields included aren't mentioned in\n654:         the result, only those that have field restrictions in place.\n655: \n656:         The \"target\" parameter is the instance that is populated (in place).\n657:         The \"callback\" is a function that is called whenever a (model, field)\n658:         pair need to be added to \"target\". It accepts three parameters:\n659:         \"target\", and the model and list of fields being added for that model.\n660:         \"\"\"\n661:         field_names, defer = self.deferred_loading\n662:         if not field_names:\n663:             return\n664:         orig_opts = self.get_meta()\n665:         seen = {}\n666:         must_include = {orig_opts.concrete_model: {orig_opts.pk}}\n667:         for field_name in field_names:\n668:             parts = field_name.split(LOOKUP_SEP)\n669:             cur_model = self.model._meta.concrete_model\n670:             opts = orig_opts\n671:             for name in parts[:-1]:\n672:                 old_model = cur_model\n673:                 if name in self._filtered_relations:\n674:                     name = self._filtered_relations[name].relation_name\n675:                 source = opts.get_field(name)\n676:                 if is_reverse_o2o(source):\n677:                     cur_model = source.related_model\n678:                 else:\n679:                     cur_model = source.remote_field.model\n680:                 opts = cur_model._meta\n681:                 # Even if we're \"just passing through\" this model, we must add\n682:                 # both the current model's pk and the related reference field\n683:                 # (if it's not a reverse relation) to the things we select.\n684:                 if not is_reverse_o2o(source):\n685:                     must_include[old_model].add(source)\n686:                 add_to_dict(must_include, cur_model, opts.pk)\n687:             field = opts.get_field(parts[-1])\n688:             is_reverse_object = field.auto_created and not field.concrete\n689:             model = field.related_model if is_reverse_object else field.model\n690:             model = model._meta.concrete_model\n691:             if model == opts.model:\n692:                 model = cur_model\n693:             if not is_reverse_o2o(field):\n694:                 add_to_dict(seen, model, field)\n695: \n696:         if defer:\n697:             # We need to load all fields for each model, except those that\n698:             # appear in \"seen\" (for all models that appear in \"seen\"). The only\n699:             # slight complexity here is handling fields that exist on parent\n700:             # models.\n701:             workset = {}\n702:             for model, values in seen.items():\n703:                 for field in model._meta.local_fields:\n704:                     if field not in values:\n705:                         m = field.model._meta.concrete_model\n706:                         add_to_dict(workset, m, field)\n707:             for model, values in must_include.items():\n708:                 # If we haven't included a model in workset, we don't add the\n709:                 # corresponding must_include fields for that model, since an\n710:                 # empty set means \"include all fields\". That's why there's no\n711:                 # \"else\" branch here.\n712:                 if model in workset:\n713:                     workset[model].update(values)\n714:             for model, values in workset.items():\n715:                 callback(target, model, values)\n716:         else:\n717:             for model, values in must_include.items():\n718:                 if model in seen:\n719:                     seen[model].update(values)\n720:                 else:\n721:                     # As we've passed through this model, but not explicitly\n722:                     # included any fields, we have to make sure it's mentioned\n723:                     # so that only the \"must include\" fields are pulled in.\n724:                     seen[model] = values\n725:             # Now ensure that every model in the inheritance chain is mentioned\n726:             # in the parent list. Again, it must be mentioned to ensure that\n727:             # only \"must include\" fields are pulled in.\n728:             for model in orig_opts.get_parent_list():\n729:                 seen.setdefault(model, set())\n730:             for model, values in seen.items():\n731:                 callback(target, model, values)\n732: \n733:     def table_alias(self, table_name, create=False, filtered_relation=None):\n734:         \"\"\"\n735:         Return a table alias for the given table_name and whether this is a\n736:         new alias or not.\n737: \n738:         If 'create' is true, a new alias is always created. Otherwise, the\n739:         most recently created alias for the table (if one exists) is reused.\n740:         \"\"\"\n741:         alias_list = self.table_map.get(table_name)\n742:         if not create and alias_list:\n743:             alias = alias_list[0]\n744:             self.alias_refcount[alias] += 1\n745:             return alias, False\n746: \n747:         # Create a new alias for this table.\n748:         if alias_list:\n749:             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)\n750:             alias_list.append(alias)\n751:         else:\n752:             # The first occurrence of a table uses the table name directly.\n753:             alias = filtered_relation.alias if filtered_relation is not None else table_name\n754:             self.table_map[table_name] = [alias]\n755:         self.alias_refcount[alias] = 1\n756:         return alias, True\n757: \n758:     def ref_alias(self, alias):\n759:         \"\"\"Increases the reference count for this alias.\"\"\"\n760:         self.alias_refcount[alias] += 1\n761: \n762:     def unref_alias(self, alias, amount=1):\n763:         \"\"\"Decreases the reference count for this alias.\"\"\"\n764:         self.alias_refcount[alias] -= amount\n765: \n766:     def promote_joins(self, aliases):\n767:         \"\"\"\n768:         Promote recursively the join type of given aliases and its children to\n769:         an outer join. If 'unconditional' is False, only promote the join if\n770:         it is nullable or the parent join is an outer join.\n771: \n772:         The children promotion is done to avoid join chains that contain a LOUTER\n773:         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,\n774:         then we must also promote b->c automatically, or otherwise the promotion\n775:         of a->b doesn't actually change anything in the query results.\n776:         \"\"\"\n777:         aliases = list(aliases)\n778:         while aliases:\n779:             alias = aliases.pop(0)\n780:             if self.alias_map[alias].join_type is None:\n781:                 # This is the base table (first FROM entry) - this table\n782:                 # isn't really joined at all in the query, so we should not\n783:                 # alter its join type.\n784:                 continue\n785:             # Only the first alias (skipped above) should have None join_type\n786:             assert self.alias_map[alias].join_type is not None\n787:             parent_alias = self.alias_map[alias].parent_alias\n788:             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER\n789:             already_louter = self.alias_map[alias].join_type == LOUTER\n790:             if ((self.alias_map[alias].nullable or parent_louter) and\n791:                     not already_louter):\n792:                 self.alias_map[alias] = self.alias_map[alias].promote()\n793:                 # Join type of 'alias' changed, so re-examine all aliases that\n794:                 # refer to this one.\n795:                 aliases.extend(\n796:                     join for join in self.alias_map\n797:                     if self.alias_map[join].parent_alias == alias and join not in aliases\n798:                 )\n799: \n800:     def demote_joins(self, aliases):\n801:         \"\"\"\n802:         Change join type from LOUTER to INNER for all joins in aliases.\n803: \n804:         Similarly to promote_joins(), this method must ensure no join chains\n805:         containing first an outer, then an inner join are generated. If we\n806:         are demoting b->c join in chain a LOUTER b LOUTER c then we must\n807:         demote a->b automatically, or otherwise the demotion of b->c doesn't\n808:         actually change anything in the query results. .\n809:         \"\"\"\n810:         aliases = list(aliases)\n811:         while aliases:\n812:             alias = aliases.pop(0)\n813:             if self.alias_map[alias].join_type == LOUTER:\n814:                 self.alias_map[alias] = self.alias_map[alias].demote()\n815:                 parent_alias = self.alias_map[alias].parent_alias\n816:                 if self.alias_map[parent_alias].join_type == INNER:\n817:                     aliases.append(parent_alias)\n818: \n819:     def reset_refcounts(self, to_counts):\n820:         \"\"\"\n821:         Reset reference counts for aliases so that they match the value passed\n822:         in `to_counts`.\n823:         \"\"\"\n824:         for alias, cur_refcount in self.alias_refcount.copy().items():\n825:             unref_amount = cur_refcount - to_counts.get(alias, 0)\n826:             self.unref_alias(alias, unref_amount)\n827: \n828:     def change_aliases(self, change_map):\n829:         \"\"\"\n830:         Change the aliases in change_map (which maps old-alias -> new-alias),\n831:         relabelling any references to them in select columns and the where\n832:         clause.\n833:         \"\"\"\n834:         assert set(change_map).isdisjoint(change_map.values())\n835: \n836:         # 1. Update references in \"select\" (normal columns plus aliases),\n837:         # \"group by\" and \"where\".\n838:         self.where.relabel_aliases(change_map)\n839:         if isinstance(self.group_by, tuple):\n840:             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])\n841:         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n842:         self.annotations = self.annotations and {\n843:             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()\n844:         }\n845: \n846:         # 2. Rename the alias in the internal table/alias datastructures.\n847:         for old_alias, new_alias in change_map.items():\n848:             if old_alias not in self.alias_map:\n849:                 continue\n850:             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)\n851:             self.alias_map[new_alias] = alias_data\n852:             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]\n853:             del self.alias_refcount[old_alias]\n854:             del self.alias_map[old_alias]\n855: \n856:             table_aliases = self.table_map[alias_data.table_name]\n857:             for pos, alias in enumerate(table_aliases):\n858:                 if alias == old_alias:\n859:                     table_aliases[pos] = new_alias\n860:                     break\n861:         self.external_aliases = {\n862:             # Table is aliased or it's being changed and thus is aliased.\n863:             change_map.get(alias, alias): (aliased or alias in change_map)\n864:             for alias, aliased in self.external_aliases.items()\n865:         }\n866: \n867:     def bump_prefix(self, outer_query):\n868:         \"\"\"\n869:         Change the alias prefix to the next letter in the alphabet in a way\n870:         that the outer query's aliases and this query's aliases will not\n871:         conflict. Even tables that previously had no alias will get an alias\n872:         after this call.\n873:         \"\"\"\n874:         def prefix_gen():\n875:             \"\"\"\n876:             Generate a sequence of characters in alphabetical order:\n877:                 -> 'A', 'B', 'C', ...\n878: \n879:             When the alphabet is finished, the sequence will continue with the\n880:             Cartesian product:\n881:                 -> 'AA', 'AB', 'AC', ...\n882:             \"\"\"\n883:             alphabet = ascii_uppercase\n884:             prefix = chr(ord(self.alias_prefix) + 1)\n885:             yield prefix\n886:             for n in count(1):\n887:                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet\n888:                 for s in product(seq, repeat=n):\n889:                     yield ''.join(s)\n890:                 prefix = None\n891: \n892:         if self.alias_prefix != outer_query.alias_prefix:\n893:             # No clashes between self and outer query should be possible.\n894:             return\n895: \n896:         # Explicitly avoid infinite loop. The constant divider is based on how\n897:         # much depth recursive subquery references add to the stack. This value\n898:         # might need to be adjusted when adding or removing function calls from\n899:         # the code path in charge of performing these operations.\n900:         local_recursion_limit = sys.getrecursionlimit() // 16\n901:         for pos, prefix in enumerate(prefix_gen()):\n902:             if prefix not in self.subq_aliases:\n903:                 self.alias_prefix = prefix\n904:                 break\n905:             if pos > local_recursion_limit:\n906:                 raise RecursionError(\n907:                     'Maximum recursion depth exceeded: too many subqueries.'\n908:                 )\n909:         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])\n910:         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)\n911:         self.change_aliases({\n912:             alias: '%s%d' % (self.alias_prefix, pos)\n913:             for pos, alias in enumerate(self.alias_map)\n914:         })\n915: \n916:     def get_initial_alias(self):\n917:         \"\"\"\n918:         Return the first alias for this query, after increasing its reference\n919:         count.\n920:         \"\"\"\n921:         if self.alias_map:\n922:             alias = self.base_table\n923:             self.ref_alias(alias)\n924:         else:\n925:             alias = self.join(BaseTable(self.get_meta().db_table, None))\n926:         return alias\n927: \n928:     def count_active_tables(self):\n929:         \"\"\"\n930:         Return the number of tables in this query with a non-zero reference\n931:         count. After execution, the reference counts are zeroed, so tables\n932:         added in compiler will not be seen by this method.\n933:         \"\"\"\n934:         return len([1 for count in self.alias_refcount.values() if count])\n935: \n936:     def join(self, join, reuse=None, reuse_with_filtered_relation=False):\n937:         \"\"\"\n938:         Return an alias for the 'join', either reusing an existing alias for\n939:         that join or creating a new one. 'join' is either a\n940:         sql.datastructures.BaseTable or Join.\n941: \n942:         The 'reuse' parameter can be either None which means all joins are\n943:         reusable, or it can be a set containing the aliases that can be reused.\n944: \n945:         The 'reuse_with_filtered_relation' parameter is used when computing\n946:         FilteredRelation instances.\n947: \n948:         A join is always created as LOUTER if the lhs alias is LOUTER to make\n949:         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new\n950:         joins are created as LOUTER if the join is nullable.\n951:         \"\"\"\n952:         if reuse_with_filtered_relation and reuse:\n953:             reuse_aliases = [\n954:                 a for a, j in self.alias_map.items()\n955:                 if a in reuse and j.equals(join, with_filtered_relation=False)\n956:             ]\n957:         else:\n958:             reuse_aliases = [\n959:                 a for a, j in self.alias_map.items()\n960:                 if (reuse is None or a in reuse) and j == join\n961:             ]\n962:         if reuse_aliases:\n963:             if join.table_alias in reuse_aliases:\n964:                 reuse_alias = join.table_alias\n965:             else:\n966:                 # Reuse the most recent alias of the joined table\n967:                 # (a many-to-many relation may be joined multiple times).\n968:                 reuse_alias = reuse_aliases[-1]\n969:             self.ref_alias(reuse_alias)\n970:             return reuse_alias\n971: \n972:         # No reuse is possible, so we need a new alias.\n973:         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)\n974:         if join.join_type:\n975:             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n976:                 join_type = LOUTER\n977:             else:\n978:                 join_type = INNER\n979:             join.join_type = join_type\n980:         join.table_alias = alias\n981:         self.alias_map[alias] = join\n982:         return alias\n983: \n984:     def join_parent_model(self, opts, model, alias, seen):\n985:         \"\"\"\n986:         Make sure the given 'model' is joined in the query. If 'model' isn't\n987:         a parent of 'opts' or if it is None this method is a no-op.\n988: \n989:         The 'alias' is the root alias for starting the join, 'seen' is a dict\n990:         of model -> alias of existing joins. It must also contain a mapping\n991:         of None -> some alias. This will be returned in the no-op case.\n992:         \"\"\"\n993:         if model in seen:\n994:             return seen[model]\n995:         chain = opts.get_base_chain(model)\n996:         if not chain:\n997:             return alias\n998:         curr_opts = opts\n999:         for int_model in chain:\n1000:             if int_model in seen:\n1001:                 curr_opts = int_model._meta\n1002:                 alias = seen[int_model]\n1003:                 continue\n1004:             # Proxy model have elements in base chain\n1005:             # with no parents, assign the new options\n1006:             # object and skip to the next base in that\n1007:             # case\n1008:             if not curr_opts.parents[int_model]:\n1009:                 curr_opts = int_model._meta\n1010:                 continue\n1011:             link_field = curr_opts.get_ancestor_link(int_model)\n1012:             join_info = self.setup_joins([link_field.name], curr_opts, alias)\n1013:             curr_opts = int_model._meta\n1014:             alias = seen[int_model] = join_info.joins[-1]\n1015:         return alias or seen[None]\n1016: \n1017:     def add_annotation(self, annotation, alias, is_summary=False):\n1018:         \"\"\"Add a single annotation expression to the Query.\"\"\"\n1019:         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,\n1020:                                                    summarize=is_summary)\n1021:         self.append_annotation_mask([alias])\n1022:         self.annotations[alias] = annotation\n1023: \n1024:     def resolve_expression(self, query, *args, **kwargs):\n1025:         clone = self.clone()\n1026:         # Subqueries need to use a different set of aliases than the outer query.\n1027:         clone.bump_prefix(query)\n1028:         clone.subquery = True\n1029:         # It's safe to drop ordering if the queryset isn't using slicing,\n1030:         # distinct(*fields) or select_for_update().\n1031:         if (self.low_mark == 0 and self.high_mark is None and\n1032:                 not self.distinct_fields and\n1033:                 not self.select_for_update):\n1034:             clone.clear_ordering(True)\n1035:         clone.where.resolve_expression(query, *args, **kwargs)\n1036:         for key, value in clone.annotations.items():\n1037:             resolved = value.resolve_expression(query, *args, **kwargs)\n1038:             if hasattr(resolved, 'external_aliases'):\n1039:                 resolved.external_aliases.update(clone.external_aliases)\n1040:             clone.annotations[key] = resolved\n1041:         # Outer query's aliases are considered external.\n1042:         for alias, table in query.alias_map.items():\n1043:             clone.external_aliases[alias] = (\n1044:                 (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or\n1045:                 (isinstance(table, BaseTable) and table.table_name != table.table_alias)\n1046:             )\n1047:         return clone\n1048: \n1049:     def get_external_cols(self):\n1050:         exprs = chain(self.annotations.values(), self.where.children)\n1051:         return [\n1052:             col for col in self._gen_cols(exprs)\n1053:             if col.alias in self.external_aliases\n1054:         ]\n1055: \n1056:     def as_sql(self, compiler, connection):\n1057:         sql, params = self.get_compiler(connection=connection).as_sql()\n1058:         if self.subquery:\n1059:             sql = '(%s)' % sql\n1060:         return sql, params\n1061: \n1062:     def resolve_lookup_value(self, value, can_reuse, allow_joins):\n1063:         if hasattr(value, 'resolve_expression'):\n1064:             value = value.resolve_expression(\n1065:                 self, reuse=can_reuse, allow_joins=allow_joins,\n1066:             )\n1067:         elif isinstance(value, (list, tuple)):\n1068:             # The items of the iterable may be expressions and therefore need\n1069:             # to be resolved independently.\n1070:             return type(value)(\n1071:                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n1072:                 for sub_value in value\n1073:             )\n1074:         return value\n1075: \n1076:     def solve_lookup_type(self, lookup):\n1077:         \"\"\"\n1078:         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').\n1079:         \"\"\"\n1080:         lookup_splitted = lookup.split(LOOKUP_SEP)\n1081:         if self.annotations:\n1082:             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)\n1083:             if expression:\n1084:                 return expression_lookups, (), expression\n1085:         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n1086:         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]\n1087:         if len(lookup_parts) > 1 and not field_parts:\n1088:             raise FieldError(\n1089:                 'Invalid lookup \"%s\" for model %s\".' %\n1090:                 (lookup, self.get_meta().model.__name__)\n1091:             )\n1092:         return lookup_parts, field_parts, False\n1093: \n1094:     def check_query_object_type(self, value, opts, field):\n1095:         \"\"\"\n1096:         Check whether the object passed while querying is of the correct type.\n1097:         If not, raise a ValueError specifying the wrong object.\n1098:         \"\"\"\n1099:         if hasattr(value, '_meta'):\n1100:             if not check_rel_lookup_compatibility(value._meta.model, opts, field):\n1101:                 raise ValueError(\n1102:                     'Cannot query \"%s\": Must be \"%s\" instance.' %\n1103:                     (value, opts.object_name))\n1104: \n1105:     def check_related_objects(self, field, value, opts):\n1106:         \"\"\"Check the type of object passed to query relations.\"\"\"\n1107:         if field.is_relation:\n1108:             # Check that the field and the queryset use the same model in a\n1109:             # query like .filter(author=Author.objects.all()). For example, the\n1110:             # opts would be Author's (from the author field) and value.model\n1111:             # would be Author.objects.all() queryset's .model (Author also).\n1112:             # The field is the related field on the lhs side.\n1113:             if (isinstance(value, Query) and not value.has_select_fields and\n1114:                     not check_rel_lookup_compatibility(value.model, opts, field)):\n1115:                 raise ValueError(\n1116:                     'Cannot use QuerySet for \"%s\": Use a QuerySet for \"%s\".' %\n1117:                     (value.model._meta.object_name, opts.object_name)\n1118:                 )\n1119:             elif hasattr(value, '_meta'):\n1120:                 self.check_query_object_type(value, opts, field)\n1121:             elif hasattr(value, '__iter__'):\n1122:                 for v in value:\n1123:                     self.check_query_object_type(v, opts, field)\n1124: \n1125:     def check_filterable(self, expression):\n1126:         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n1127:         if not getattr(expression, 'filterable', True):\n1128:             raise NotSupportedError(\n1129:                 expression.__class__.__name__ + ' is disallowed in the filter '\n1130:                 'clause.'\n1131:             )\n1132:         if hasattr(expression, 'get_source_expressions'):\n1133:             for expr in expression.get_source_expressions():\n1134:                 self.check_filterable(expr)\n1135: \n1136:     def build_lookup(self, lookups, lhs, rhs):\n1137:         \"\"\"\n1138:         Try to extract transforms and lookup from given lhs.\n1139: \n1140:         The lhs value is something that works like SQLExpression.\n1141:         The rhs value is what the lookup is going to compare against.\n1142:         The lookups is a list of names to extract using get_lookup()\n1143:         and get_transform().\n1144:         \"\"\"\n1145:         # __exact is the default lookup if one isn't given.\n1146:         *transforms, lookup_name = lookups or ['exact']\n1147:         for name in transforms:\n1148:             lhs = self.try_transform(lhs, name)\n1149:         # First try get_lookup() so that the lookup takes precedence if the lhs\n1150:         # supports both transform and lookup for the name.\n1151:         lookup_class = lhs.get_lookup(lookup_name)\n1152:         if not lookup_class:\n1153:             if lhs.field.is_relation:\n1154:                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))\n1155:             # A lookup wasn't found. Try to interpret the name as a transform\n1156:             # and do an Exact lookup against it.\n1157:             lhs = self.try_transform(lhs, lookup_name)\n1158:             lookup_name = 'exact'\n1159:             lookup_class = lhs.get_lookup(lookup_name)\n1160:             if not lookup_class:\n1161:                 return\n1162: \n1163:         lookup = lookup_class(lhs, rhs)\n1164:         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n1165:         # uses of None as a query value unless the lookup supports it.\n1166:         if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n1167:             if lookup_name not in ('exact', 'iexact'):\n1168:                 raise ValueError(\"Cannot use None as a query value\")\n1169:             return lhs.get_lookup('isnull')(lhs, True)\n1170: \n1171:         # For Oracle '' is equivalent to null. The check must be done at this\n1172:         # stage because join promotion can't be done in the compiler. Using\n1173:         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n1174:         # A similar thing is done in is_nullable(), too.\n1175:         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and\n1176:                 lookup_name == 'exact' and lookup.rhs == ''):\n1177:             return lhs.get_lookup('isnull')(lhs, True)\n1178: \n1179:         return lookup\n1180: \n1181:     def try_transform(self, lhs, name):\n1182:         \"\"\"\n1183:         Helper method for build_lookup(). Try to fetch and initialize\n1184:         a transform for name parameter from lhs.\n1185:         \"\"\"\n1186:         transform_class = lhs.get_transform(name)\n1187:         if transform_class:\n1188:             return transform_class(lhs)\n1189:         else:\n1190:             output_field = lhs.output_field.__class__\n1191:             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())\n1192:             if suggested_lookups:\n1193:                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)\n1194:             else:\n... Code Truncated ...\n\n",
  "line_level_localization": [
    {
      "filename": "/django/db/models/sql/query.py",
      "suspect_lines": [
        1127
      ]
    }
  ]
}