{
  "repo": "matplotlib/matplotlib",
  "instance_id": "matplotlib__matplotlib-20488",
  "base_commit": "b7ce415c15eb39b026a097a2865da73fbcf15c9c",
  "patch": "diff --git a/lib/matplotlib/image.py b/lib/matplotlib/image.py\n--- a/lib/matplotlib/image.py\n+++ b/lib/matplotlib/image.py\n@@ -532,9 +532,9 @@ def _make_image(self, A, in_bbox, out_bbox, clip_bbox, magnification=1.0,\n                 # we have re-set the vmin/vmax to account for small errors\n                 # that may have moved input values in/out of range\n                 s_vmin, s_vmax = vrange\n-                if isinstance(self.norm, mcolors.LogNorm):\n-                    if s_vmin < 0:\n-                        s_vmin = max(s_vmin, np.finfo(scaled_dtype).eps)\n+                if isinstance(self.norm, mcolors.LogNorm) and s_vmin <= 0:\n+                    # Don't give 0 or negative values to LogNorm\n+                    s_vmin = np.finfo(scaled_dtype).eps\n                 with cbook._setattr_cm(self.norm,\n                                        vmin=s_vmin,\n                                        vmax=s_vmax,\n",
  "test_patch": "diff --git a/lib/matplotlib/tests/test_image.py b/lib/matplotlib/tests/test_image.py\n--- a/lib/matplotlib/tests/test_image.py\n+++ b/lib/matplotlib/tests/test_image.py\n@@ -1233,23 +1233,24 @@ def test_imshow_quantitynd():\n     fig.canvas.draw()\n \n \n+@pytest.mark.parametrize('x', [-1, 1])\n @check_figures_equal(extensions=['png'])\n-def test_huge_range_log(fig_test, fig_ref):\n-    data = np.full((5, 5), -1, dtype=np.float64)\n+def test_huge_range_log(fig_test, fig_ref, x):\n+    # parametrize over bad lognorm -1 values and large range 1 -> 1e20\n+    data = np.full((5, 5), x, dtype=np.float64)\n     data[0:2, :] = 1E20\n \n     ax = fig_test.subplots()\n-    im = ax.imshow(data, norm=colors.LogNorm(vmin=100, vmax=data.max()),\n-                   interpolation='nearest', cmap='viridis')\n+    ax.imshow(data, norm=colors.LogNorm(vmin=1, vmax=data.max()),\n+              interpolation='nearest', cmap='viridis')\n \n-    data = np.full((5, 5), -1, dtype=np.float64)\n+    data = np.full((5, 5), x, dtype=np.float64)\n     data[0:2, :] = 1000\n \n-    cmap = copy(plt.get_cmap('viridis'))\n-    cmap.set_under('w')\n     ax = fig_ref.subplots()\n-    im = ax.imshow(data, norm=colors.Normalize(vmin=100, vmax=data.max()),\n-                   interpolation='nearest', cmap=cmap)\n+    cmap = plt.get_cmap('viridis').with_extremes(under='w')\n+    ax.imshow(data, norm=colors.Normalize(vmin=1, vmax=data.max()),\n+              interpolation='nearest', cmap=cmap)\n \n \n @check_figures_equal()\n",
  "problem_statement": "test_huge_range_log is failing...\n<!--To help us understand and resolve your issue, please fill out the form to the best of your ability.-->\r\n<!--You can feel free to delete the sections that do not apply.-->\r\n\r\n### Bug report\r\n\r\n`lib/matplotlib/tests/test_image.py::test_huge_range_log` is failing quite a few of the CI runs with a Value Error.  \r\n\r\nI cannot reproduce locally, so I assume there was a numpy change somewhere...\r\n\r\nThis test came in #18458\r\n\r\n\r\n```\r\nlib/matplotlib/image.py:638: in draw\r\n    im, l, b, trans = self.make_image(\r\nlib/matplotlib/image.py:924: in make_image\r\n    return self._make_image(self._A, bbox, transformed_bbox, clip,\r\nlib/matplotlib/image.py:542: in _make_image\r\n    output = self.norm(resampled_masked)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <matplotlib.colors.LogNorm object at 0x7f057193f430>\r\nvalue = masked_array(\r\n  data=[[--, --, --, ..., --, --, --],\r\n        [--, --, --, ..., --, --, --],\r\n        [--, --, --, ..., ... False, False, ..., False, False, False],\r\n        [False, False, False, ..., False, False, False]],\r\n  fill_value=1e+20)\r\nclip = False\r\n\r\n    def __call__(self, value, clip=None):\r\n        value, is_scalar = self.process_value(value)\r\n        self.autoscale_None(value)\r\n        if self.vmin > self.vmax:\r\n            raise ValueError(\"vmin must be less or equal to vmax\")\r\n        if self.vmin == self.vmax:\r\n            return np.full_like(value, 0)\r\n        if clip is None:\r\n            clip = self.clip\r\n        if clip:\r\n            value = np.clip(value, self.vmin, self.vmax)\r\n        t_value = self._trf.transform(value).reshape(np.shape(value))\r\n        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\r\n        if not np.isfinite([t_vmin, t_vmax]).all():\r\n>           raise ValueError(\"Invalid vmin or vmax\")\r\nE           ValueError: Invalid vmin or vmax\r\nlib/matplotlib/colors.py:1477: ValueError\r\n```\r\n\r\n\n",
  "hints_text": "Yeah, OK, np 1.21.0 dropped 8hr ago... ",
  "created_at": "2021-06-23T03:05:05Z",
  "version": "3.4",
  "FAIL_TO_PASS": "[\"lib/matplotlib/tests/test_image.py::test_huge_range_log[png--1]\"]",
  "PASS_TO_PASS": "[\"lib/matplotlib/tests/test_image.py::test_image_interps[png]\", \"lib/matplotlib/tests/test_image.py::test_image_interps[pdf]\", \"lib/matplotlib/tests/test_image.py::test_alpha_interp[png]\", \"lib/matplotlib/tests/test_image.py::test_figimage[png-False]\", \"lib/matplotlib/tests/test_image.py::test_figimage[png-True]\", \"lib/matplotlib/tests/test_image.py::test_figimage[pdf-False]\", \"lib/matplotlib/tests/test_image.py::test_figimage[pdf-True]\", \"lib/matplotlib/tests/test_image.py::test_image_python_io\", \"lib/matplotlib/tests/test_image.py::test_imshow_antialiased[png-5-2-hanning]\", \"lib/matplotlib/tests/test_image.py::test_imshow_antialiased[png-5-5-nearest]\", \"lib/matplotlib/tests/test_image.py::test_imshow_antialiased[png-5-10-nearest]\", \"lib/matplotlib/tests/test_image.py::test_imshow_antialiased[png-3-2.9-hanning]\", \"lib/matplotlib/tests/test_image.py::test_imshow_antialiased[png-3-9.1-nearest]\", \"lib/matplotlib/tests/test_image.py::test_imshow_zoom[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_pil[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_pil[pdf]\", \"lib/matplotlib/tests/test_image.py::test_imread_pil_uint16\", \"lib/matplotlib/tests/test_image.py::test_imread_fspath\", \"lib/matplotlib/tests/test_image.py::test_imsave[png]\", \"lib/matplotlib/tests/test_image.py::test_imsave[jpg]\", \"lib/matplotlib/tests/test_image.py::test_imsave[jpeg]\", \"lib/matplotlib/tests/test_image.py::test_imsave[tiff]\", \"lib/matplotlib/tests/test_image.py::test_imsave_fspath[png]\", \"lib/matplotlib/tests/test_image.py::test_imsave_fspath[pdf]\", \"lib/matplotlib/tests/test_image.py::test_imsave_fspath[ps]\", \"lib/matplotlib/tests/test_image.py::test_imsave_fspath[eps]\", \"lib/matplotlib/tests/test_image.py::test_imsave_fspath[svg]\", \"lib/matplotlib/tests/test_image.py::test_imsave_color_alpha\", \"lib/matplotlib/tests/test_image.py::test_imsave_pil_kwargs_png\", \"lib/matplotlib/tests/test_image.py::test_imsave_pil_kwargs_tiff\", \"lib/matplotlib/tests/test_image.py::test_image_alpha[png]\", \"lib/matplotlib/tests/test_image.py::test_image_alpha[pdf]\", \"lib/matplotlib/tests/test_image.py::test_cursor_data\", \"lib/matplotlib/tests/test_image.py::test_format_cursor_data[data0-[1e+04]-[10001]]\", \"lib/matplotlib/tests/test_image.py::test_format_cursor_data[data1-[0.123]-[0.123]]\", \"lib/matplotlib/tests/test_image.py::test_image_clip[png]\", \"lib/matplotlib/tests/test_image.py::test_image_cliprect[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow[pdf]\", \"lib/matplotlib/tests/test_image.py::test_imshow_10_10_1[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_10_10_2\", \"lib/matplotlib/tests/test_image.py::test_imshow_10_10_5\", \"lib/matplotlib/tests/test_image.py::test_no_interpolation_origin[png]\", \"lib/matplotlib/tests/test_image.py::test_no_interpolation_origin[pdf]\", \"lib/matplotlib/tests/test_image.py::test_image_shift[pdf]\", \"lib/matplotlib/tests/test_image.py::test_image_edges\", \"lib/matplotlib/tests/test_image.py::test_image_composite_background[png]\", \"lib/matplotlib/tests/test_image.py::test_image_composite_alpha[png]\", \"lib/matplotlib/tests/test_image.py::test_image_composite_alpha[pdf]\", \"lib/matplotlib/tests/test_image.py::test_clip_path_disables_compositing[pdf]\", \"lib/matplotlib/tests/test_image.py::test_bbox_image_inverted[png]\", \"lib/matplotlib/tests/test_image.py::test_get_window_extent_for_AxisImage\", \"lib/matplotlib/tests/test_image.py::test_zoom_and_clip_upper_origin[png]\", \"lib/matplotlib/tests/test_image.py::test_nonuniformimage_setcmap\", \"lib/matplotlib/tests/test_image.py::test_nonuniformimage_setnorm\", \"lib/matplotlib/tests/test_image.py::test_jpeg_2d\", \"lib/matplotlib/tests/test_image.py::test_jpeg_alpha\", \"lib/matplotlib/tests/test_image.py::test_axesimage_setdata\", \"lib/matplotlib/tests/test_image.py::test_figureimage_setdata\", \"lib/matplotlib/tests/test_image.py::test_setdata_xya[NonUniformImage-x0-y0-a0]\", \"lib/matplotlib/tests/test_image.py::test_setdata_xya[PcolorImage-x1-y1-a1]\", \"lib/matplotlib/tests/test_image.py::test_minimized_rasterized\", \"lib/matplotlib/tests/test_image.py::test_load_from_url\", \"lib/matplotlib/tests/test_image.py::test_log_scale_image[png]\", \"lib/matplotlib/tests/test_image.py::test_log_scale_image[pdf]\", \"lib/matplotlib/tests/test_image.py::test_rotate_image[png]\", \"lib/matplotlib/tests/test_image.py::test_rotate_image[pdf]\", \"lib/matplotlib/tests/test_image.py::test_image_preserve_size\", \"lib/matplotlib/tests/test_image.py::test_image_preserve_size2\", \"lib/matplotlib/tests/test_image.py::test_mask_image_over_under[png]\", \"lib/matplotlib/tests/test_image.py::test_mask_image[png]\", \"lib/matplotlib/tests/test_image.py::test_mask_image_all\", \"lib/matplotlib/tests/test_image.py::test_imshow_endianess[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_masked_interpolation[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_masked_interpolation[pdf]\", \"lib/matplotlib/tests/test_image.py::test_imshow_no_warn_invalid\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype0]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype1]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype2]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype3]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype4]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype5]\", \"lib/matplotlib/tests/test_image.py::test_imshow_clips_rgb_to_valid_range[dtype6]\", \"lib/matplotlib/tests/test_image.py::test_imshow_flatfield[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_bignumbers[png]\", \"lib/matplotlib/tests/test_image.py::test_imshow_bignumbers_real[png]\", \"lib/matplotlib/tests/test_image.py::test_empty_imshow[Normalize]\", \"lib/matplotlib/tests/test_image.py::test_empty_imshow[LogNorm]\", \"lib/matplotlib/tests/test_image.py::test_empty_imshow[<lambda>0]\", \"lib/matplotlib/tests/test_image.py::test_empty_imshow[<lambda>1]\", \"lib/matplotlib/tests/test_image.py::test_imshow_float16\", \"lib/matplotlib/tests/test_image.py::test_imshow_float128\", \"lib/matplotlib/tests/test_image.py::test_imshow_bool\", \"lib/matplotlib/tests/test_image.py::test_composite[True-1-ps-\", \"lib/matplotlib/tests/test_image.py::test_composite[True-1-svg-<image]\", \"lib/matplotlib/tests/test_image.py::test_composite[False-2-ps-\", \"lib/matplotlib/tests/test_image.py::test_composite[False-2-svg-<image]\", \"lib/matplotlib/tests/test_image.py::test_relim\", \"lib/matplotlib/tests/test_image.py::test_unclipped\", \"lib/matplotlib/tests/test_image.py::test_respects_bbox\", \"lib/matplotlib/tests/test_image.py::test_image_cursor_formatting\", \"lib/matplotlib/tests/test_image.py::test_image_array_alpha[png]\", \"lib/matplotlib/tests/test_image.py::test_image_array_alpha[pdf]\", \"lib/matplotlib/tests/test_image.py::test_image_array_alpha_validation\", \"lib/matplotlib/tests/test_image.py::test_exact_vmin\", \"lib/matplotlib/tests/test_image.py::test_https_imread_smoketest\", \"lib/matplotlib/tests/test_image.py::test_quantitynd\", \"lib/matplotlib/tests/test_image.py::test_huge_range_log[png-1]\", \"lib/matplotlib/tests/test_image.py::test_spy_box[png]\", \"lib/matplotlib/tests/test_image.py::test_spy_box[pdf]\", \"lib/matplotlib/tests/test_image.py::test_nonuniform_and_pcolor[png]\"]",
  "environment_setup_commit": "f93c0a3dcb82feed0262d758626c90d4002685f3",
  "difficulty": "15 min - 1 hour",
  "test_context": null,
  "localized_code": "[start of lib/matplotlib/colors.py]\n1467|                 raise ValueError(\"vmin must be less or equal to vmax\")\n1468|             if self.vmin == self.vmax:\n1469|                 return np.full_like(value, 0)\n1470|             if clip is None:\n1471|                 clip = self.clip\n1472|             if clip:\n1473|                 value = np.clip(value, self.vmin, self.vmax)\n1474|             t_value = self._trf.transform(value).reshape(np.shape(value))\n1475|             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n1476|             if not np.isfinite([t_vmin, t_vmax]).all():\n1477|                 raise ValueError(\"Invalid vmin or vmax\")\n1478|             t_value -= t_vmin\n1479|             t_value /= (t_vmax - t_vmin)\n1480|             t_value = np.ma.masked_invalid(t_value, copy=False)\n1481|             return t_value[0] if is_scalar else t_value\n1482| \n1483|         def inverse(self, value):\n1484|             if not self.scaled():\n1485|                 raise ValueError(\"Not invertible until scaled\")\n1486|             if self.vmin > self.vmax:\n1487|                 raise ValueError(\"vmin must be less or equal to vmax\")\n1488|             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n1489|             if not np.isfinite([t_vmin, t_vmax]).all():\n1490|                 raise ValueError(\"Invalid vmin or vmax\")\n1491|             value, is_scalar = self.process_value(value)\n1492|             rescaled = value * (t_vmax - t_vmin)\n1493|             rescaled += t_vmin\n1494|             value = (self._trf\n1495|                      .inverted()\n1496|                      .transform(rescaled)\n1497|                      .reshape(np.shape(value)))\n1498|             return value[0] if is_scalar else value\n1499| \n1500|     Norm.__name__ = base_norm_cls.__name__\n1501|     Norm.__qualname__ = base_norm_cls.__qualname__\n1502|     Norm.__module__ = base_norm_cls.__module__\n1503|     Norm.__init__.__signature__ = bound_init_signature.replace(parameters=[\n1504|         inspect.Parameter(\"self\", inspect.Parameter.POSITIONAL_OR_KEYWORD),\n1505|         *bound_init_signature.parameters.values()])\n1506|     return Norm\n1507| \n1508| \n1509| @_make_norm_from_scale(\n1510|     scale.FuncScale,\n1511|     init=lambda functions, vmin=None, vmax=None, clip=False: None)\n1512| class FuncNorm(Normalize):\n1513|     \"\"\"\n1514|     Arbitrary normalization using functions for the forward and inverse.\n1515| \n1516|     Parameters\n1517|     ----------\n1518|     functions : (callable, callable)\n1519|         two-tuple of the forward and inverse functions for the normalization.\n1520|         The forward function must be monotonic.\n1521| \n1522|         Both functions must have the signature ::\n1523| \n1524|            def forward(values: array-like) -> array-like\n1525| \n1526|     vmin, vmax : float or None\n1527|         If *vmin* and/or *vmax* is not given, they are initialized from the\n1528|         minimum and maximum value, respectively, of the first input\n1529|         processed; i.e., ``__call__(A)`` calls ``autoscale_None(A)``.\n1530| \n1531|     clip : bool, default: False\n1532|         If ``True`` values falling outside the range ``[vmin, vmax]``,\n1533|         are mapped to 0 or 1, whichever is closer, and masked values are\n1534|         set to 1.  If ``False`` masked values remain masked.\n1535| \n1536|         Clipping silently defeats the purpose of setting the over, under,\n1537|         and masked colors in a colormap, so it is likely to lead to\n1538|         surprises; therefore the default is ``clip=False``.\n1539|     \"\"\"\n1540| \n1541| \n1542| @_make_norm_from_scale(functools.partial(scale.LogScale, nonpositive=\"mask\"))\n1543| class LogNorm(Normalize):\n1544|     \"\"\"Normalize a given value to the 0-1 range on a log scale.\"\"\"\n1545| \n1546|     def autoscale(self, A):\n1547|         # docstring inherited.\n1548|         super().autoscale(np.ma.masked_less_equal(A, 0, copy=False))\n1549| \n1550|     def autoscale_None(self, A):\n1551|         # docstring inherited.\n1552|         super().autoscale_None(np.ma.masked_less_equal(A, 0, copy=False))\n1553| \n1554| \n1555| @_make_norm_from_scale(\n1556|     scale.SymmetricalLogScale,\n1557|     init=lambda linthresh, linscale=1., vmin=None, vmax=None, clip=False, *,\n1558|                 base=10: None)\n1559| class SymLogNorm(Normalize):\n1560|     \"\"\"\n1561|     The symmetrical logarithmic scale is logarithmic in both the\n1562|     positive and negative directions from the origin.\n1563| \n1564|     Since the values close to zero tend toward infinity, there is a\n1565|     need to have a range around zero that is linear.  The parameter\n1566|     *linthresh* allows the user to specify the size of this range\n1567|     (-*linthresh*, *linthresh*).\n1568| \n1569|     Parameters\n1570|     ----------\n1571|     linthresh : float\n1572|         The range within which the plot is linear (to avoid having the plot\n1573|         go to infinity around zero).\n1574|     linscale : float, default: 1\n1575|         This allows the linear range (-*linthresh* to *linthresh*) to be\n1576|         stretched relative to the logarithmic range. Its value is the\n1577|         number of decades to use for each half of the linear range. For\n1578|         example, when *linscale* == 1.0 (the default), the space used for\n1579|         the positive and negative halves of the linear range will be equal\n1580|         to one decade in the logarithmic range.\n1581|     base : float, default: 10\n1582|     \"\"\"\n1583| \n1584|     @property\n1585|     def linthresh(self):\n1586|         return self._scale.linthresh\n1587| \n1588|     @linthresh.setter\n1589|     def linthresh(self, value):\n1590|         self._scale.linthresh = value\n1591| \n1592| \n1593| class PowerNorm(Normalize):\n1594|     \"\"\"\n1595|     Linearly map a given value to the 0-1 range and then apply\n1596|     a power-law normalization over that range.\n1597|     \"\"\"\n1598|     def __init__(self, gamma, vmin=None, vmax=None, clip=False):\n1599|         super().__init__(vmin, vmax, clip)\n1600|         self.gamma = gamma\n1601| \n1602|     def __call__(self, value, clip=None):\n1603|         if clip is None:\n1604|             clip = self.clip\n1605| \n1606|         result, is_scalar = self.process_value(value)\n1607| \n1608|         self.autoscale_None(result)\n1609|         gamma = self.gamma\n1610|         vmin, vmax = self.vmin, self.vmax\n1611|         if vmin > vmax:\n1612|             raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n1613|         elif vmin == vmax:\n1614|             result.fill(0)\n1615|         else:\n1616|             if clip:\n1617|                 mask = np.ma.getmask(result)\n1618|                 result = np.ma.array(np.clip(result.filled(vmax), vmin, vmax),\n1619|                                      mask=mask)\n1620|             resdat = result.data\n1621|             resdat -= vmin\n1622|             resdat[resdat < 0] = 0\n1623|             np.power(resdat, gamma, resdat)\n1624|             resdat /= (vmax - vmin) ** gamma\n1625| \n1626|             result = np.ma.array(resdat, mask=result.mask, copy=False)\n1627|         if is_scalar:\n1628|             result = result[0]\n1629|         return result\n1630| \n1631|     def inverse(self, value):\n1632|         if not self.scaled():\n1633|             raise ValueError(\"Not invertible until scaled\")\n1634|         gamma = self.gamma\n1635|         vmin, vmax = self.vmin, self.vmax\n1636| \n1637|         if np.iterable(value):\n1638|             val = np.ma.asarray(value)\n1639|             return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n1640|         else:\n1641|             return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n1642| \n1643| \n1644| class BoundaryNorm(Normalize):\n1645|     \"\"\"\n1646|     Generate a colormap index based on discrete intervals.\n1647| \n1648|     Unlike `Normalize` or `LogNorm`, `BoundaryNorm` maps values to integers\n1649|     instead of to the interval 0-1.\n1650| \n... Code Truncated ...\n\n[start of lib/matplotlib/image.py]\n441|                             f\"{scaled_dtype} for imshow\")\n442|                 else:\n443|                     # probably an integer of some type.\n444|                     da = a_max.astype(np.float64) - a_min.astype(np.float64)\n445|                     # give more breathing room if a big dynamic range\n446|                     scaled_dtype = np.float64 if da > 1e8 else np.float32\n447| \n448|                 # scale the input data to [.1, .9].  The Agg\n449|                 # interpolators clip to [0, 1] internally, use a\n450|                 # smaller input scale to identify which of the\n451|                 # interpolated points need to be should be flagged as\n452|                 # over / under.\n453|                 # This may introduce numeric instabilities in very broadly\n454|                 # scaled data\n455|                 # Always copy, and don't allow array subtypes.\n456|                 A_scaled = np.array(A, dtype=scaled_dtype)\n457|                 # clip scaled data around norm if necessary.\n458|                 # This is necessary for big numbers at the edge of\n459|                 # float64's ability to represent changes.  Applying\n460|                 # a norm first would be good, but ruins the interpolation\n461|                 # of over numbers.\n462|                 self.norm.autoscale_None(A)\n463|                 dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)\n464|                 vmid = np.float64(self.norm.vmin) + dv / 2\n465|                 fact = 1e7 if scaled_dtype == np.float64 else 1e4\n466|                 newmin = vmid - dv * fact\n467|                 if newmin < a_min:\n468|                     newmin = None\n469|                 else:\n470|                     a_min = np.float64(newmin)\n471|                 newmax = vmid + dv * fact\n472|                 if newmax > a_max:\n473|                     newmax = None\n474|                 else:\n475|                     a_max = np.float64(newmax)\n476|                 if newmax is not None or newmin is not None:\n477|                     np.clip(A_scaled, newmin, newmax, out=A_scaled)\n478| \n479|                 # used to rescale the raw data to [offset, 1-offset]\n480|                 # so that the resampling code will run cleanly.  Using\n481|                 # dyadic numbers here could reduce the error, but\n482|                 # would not full eliminate it and breaks a number of\n483|                 # tests (due to the slightly different error bouncing\n484|                 # some pixels across a boundary in the (very\n485|                 # quantized) colormapping step).\n486|                 offset = .1\n487|                 frac = .8\n488|                 # we need to run the vmin/vmax through the same rescaling\n489|                 # that we run the raw data through because there are small\n490|                 # errors in the round-trip due to float precision.  If we\n491|                 # do not run the vmin/vmax through the same pipeline we can\n492|                 # have values close or equal to the boundaries end up on the\n493|                 # wrong side.\n494|                 vmin, vmax = self.norm.vmin, self.norm.vmax\n495|                 if vmin is np.ma.masked:\n496|                     vmin, vmax = a_min, a_max\n497|                 vrange = np.array([vmin, vmax], dtype=scaled_dtype)\n498| \n499|                 A_scaled -= a_min\n500|                 vrange -= a_min\n501|                 # a_min and a_max might be ndarray subclasses so use\n502|                 # item to avoid errors\n503|                 a_min = a_min.astype(scaled_dtype).item()\n504|                 a_max = a_max.astype(scaled_dtype).item()\n505| \n506|                 if a_min != a_max:\n507|                     A_scaled /= ((a_max - a_min) / frac)\n508|                     vrange /= ((a_max - a_min) / frac)\n509|                 A_scaled += offset\n510|                 vrange += offset\n511|                 # resample the input data to the correct resolution and shape\n512|                 A_resampled = _resample(self, A_scaled, out_shape, t)\n513|                 # done with A_scaled now, remove from namespace to be sure!\n514|                 del A_scaled\n515|                 # un-scale the resampled data to approximately the\n516|                 # original range things that interpolated to above /\n517|                 # below the original min/max will still be above /\n518|                 # below, but possibly clipped in the case of higher order\n519|                 # interpolation + drastically changing data.\n520|                 A_resampled -= offset\n521|                 vrange -= offset\n522|                 if a_min != a_max:\n523|                     A_resampled *= ((a_max - a_min) / frac)\n524|                     vrange *= ((a_max - a_min) / frac)\n525|                 A_resampled += a_min\n526|                 vrange += a_min\n527|                 # if using NoNorm, cast back to the original datatype\n528|                 if isinstance(self.norm, mcolors.NoNorm):\n529|                     A_resampled = A_resampled.astype(A.dtype)\n530| \n531|                 mask = (np.where(A.mask, np.float32(np.nan), np.float32(1))\n532|                         if A.mask.shape == A.shape  # nontrivial mask\n533|                         else np.ones_like(A, np.float32))\n534|                 # we always have to interpolate the mask to account for\n535|                 # non-affine transformations\n536|                 out_alpha = _resample(self, mask, out_shape, t, resample=True)\n537|                 # done with the mask now, delete from namespace to be sure!\n538|                 del mask\n539|                 # Agg updates out_alpha in place.  If the pixel has no image\n540|                 # data it will not be updated (and still be 0 as we initialized\n541|                 # it), if input data that would go into that output pixel than\n542|                 # it will be `nan`, if all the input data for a pixel is good\n543|                 # it will be 1, and if there is _some_ good data in that output\n544|                 # pixel it will be between [0, 1] (such as a rotated image).\n545|                 out_mask = np.isnan(out_alpha)\n546|                 out_alpha[out_mask] = 1\n547|                 # Apply the pixel-by-pixel alpha values if present\n548|                 alpha = self.get_alpha()\n549|                 if alpha is not None and np.ndim(alpha) > 0:\n550|                     out_alpha *= _resample(self, alpha, out_shape,\n551|                                            t, resample=True)\n552|                 # mask and run through the norm\n553|                 resampled_masked = np.ma.masked_array(A_resampled, out_mask)\n554|                 # we have re-set the vmin/vmax to account for small errors\n555|                 # that may have moved input values in/out of range\n556|                 s_vmin, s_vmax = vrange\n557|                 if isinstance(self.norm, mcolors.LogNorm):\n558|                     if s_vmin < 0:\n559|                         s_vmin = max(s_vmin, np.finfo(scaled_dtype).eps)\n560|                 with cbook._setattr_cm(self.norm,\n561|                                        vmin=s_vmin,\n562|                                        vmax=s_vmax,\n563|                                        ):\n564|                     output = self.norm(resampled_masked)\n565|             else:\n566|                 if A.shape[2] == 3:\n567|                     A = _rgb_to_rgba(A)\n568|                 alpha = self._get_scalar_alpha()\n569|                 output_alpha = _resample(  # resample alpha channel\n570|                     self, A[..., 3], out_shape, t, alpha=alpha)\n571|                 output = _resample(  # resample rgb channels\n572|                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n573|                 output[..., 3] = output_alpha  # recombine rgb and alpha\n574| \n575|             # at this point output is either a 2D array of normed data\n576|             # (of int or float)\n577|             # or an RGBA array of re-sampled input\n578|             output = self.to_rgba(output, bytes=True, norm=False)\n579|             # output is now a correctly sized RGBA array of uint8\n580| \n581|             # Apply alpha *after* if the input was greyscale without a mask\n582|             if A.ndim == 2:\n583|                 alpha = self._get_scalar_alpha()\n584|                 alpha_channel = output[:, :, 3]\n585|                 alpha_channel[:] = np.asarray(\n586|                     np.asarray(alpha_channel, np.float32) * out_alpha * alpha,\n587|                     np.uint8)\n588| \n589|         else:\n590|             if self._imcache is None:\n591|                 self._imcache = self.to_rgba(A, bytes=True, norm=(A.ndim == 2))\n592|             output = self._imcache\n593| \n594|             # Subset the input image to only the part that will be\n595|             # displayed\n596|             subset = TransformedBbox(clip_bbox, t0.inverted()).frozen()\n597|             output = output[\n598|                 int(max(subset.ymin, 0)):\n599|                 int(min(subset.ymax + 1, output.shape[0])),\n600|                 int(max(subset.xmin, 0)):\n601|                 int(min(subset.xmax + 1, output.shape[1]))]\n602| \n603|             t = Affine2D().translate(\n604|                 int(max(subset.xmin, 0)), int(max(subset.ymin, 0))) + t\n605| \n606|         return output, clipped_bbox.x0, clipped_bbox.y0, t\n607| \n608|     def make_image(self, renderer, magnification=1.0, unsampled=False):\n609|         \"\"\"\n610|         Normalize, rescale, and colormap this image's data for rendering using\n611|         *renderer*, with the given *magnification*.\n612| \n613|         If *unsampled* is True, the image will not be scaled, but an\n614|         appropriate affine transformation will be returned instead.\n615| \n616|         Returns\n617|         -------\n618|         image : (M, N, 4) uint8 array\n619|             The RGBA image, resampled unless *unsampled* is True.\n620|         x, y : float\n621|             The upper left corner where the image should be drawn, in pixel\n622|             space.\n623|         trans : Affine2D\n624|             The affine transformation from image to pixel space.\n625|         \"\"\"\n626|         raise NotImplementedError('The make_image method must be overridden')\n627| \n628|     def _check_unsampled_image(self):\n629|         \"\"\"\n630|         Return whether the image is better to be drawn unsampled.\n631| \n632|         The derived class needs to override it.\n633|         \"\"\"\n634|         return False\n635| \n636|     @martist.allow_rasterization\n637|     def draw(self, renderer, *args, **kwargs):\n638|         # if not visible, declare victory and return\n639|         if not self.get_visible():\n640|             self.stale = False\n641|             return\n642|         # for empty images, there is nothing to draw!\n643|         if self.get_array().size == 0:\n644|             self.stale = False\n645|             return\n646|         # actually render the image.\n647|         gc = renderer.new_gc()\n648|         self._set_gc_clip(gc)\n649|         gc.set_alpha(self._get_scalar_alpha())\n650|         gc.set_url(self.get_url())\n651|         gc.set_gid(self.get_gid())\n652|         if (renderer.option_scale_image()  # Renderer supports transform kwarg.\n653|                 and self._check_unsampled_image()\n654|                 and self.get_transform().is_affine):\n655|             im, l, b, trans = self.make_image(renderer, unsampled=True)\n656|             if im is not None:\n657|                 trans = Affine2D().scale(im.shape[1], im.shape[0]) + trans\n658|                 renderer.draw_image(gc, l, b, im, trans)\n659|         else:\n660|             im, l, b, trans = self.make_image(\n661|                 renderer, renderer.get_image_magnification())\n662|             if im is not None:\n663|                 renderer.draw_image(gc, l, b, im)\n664|         gc.restore()\n665|         self.stale = False\n666| \n667|     def contains(self, mouseevent):\n668|         \"\"\"Test whether the mouse event occurred within the image.\"\"\"\n669|         inside, info = self._default_contains(mouseevent)\n670|         if inside is not None:\n671|             return inside, info\n672|         # 1) This doesn't work for figimage; but figimage also needs a fix\n673|         #    below (as the check cannot use x/ydata and extents).\n674|         # 2) As long as the check below uses x/ydata, we need to test axes\n675|         #    identity instead of `self.axes.contains(event)` because even if\n676|         #    axes overlap, x/ydata is only valid for event.inaxes anyways.\n677|         if self.axes is not mouseevent.inaxes:\n678|             return False, {}\n679|         # TODO: make sure this is consistent with patch and patch\n680|         # collection on nonlinear transformed coordinates.\n681|         # TODO: consider returning image coordinates (shouldn't\n682|         # be too difficult given that the image is rectilinear\n683|         trans = self.get_transform().inverted()\n684|         x, y = trans.transform([mouseevent.x, mouseevent.y])\n685|         xmin, xmax, ymin, ymax = self.get_extent()\n686|         if xmin > xmax:\n687|             xmin, xmax = xmax, xmin\n688|         if ymin > ymax:\n689|             ymin, ymax = ymax, ymin\n690| \n691|         if x is not None and y is not None:\n692|             inside = (xmin <= x <= xmax) and (ymin <= y <= ymax)\n693|         else:\n694|             inside = False\n695| \n696|         return inside, {}\n697| \n698|     def write_png(self, fname):\n699|         \"\"\"Write the image to png file *fname*.\"\"\"\n700|         im = self.to_rgba(self._A[::-1] if self.origin == 'lower' else self._A,\n701|                           bytes=True, norm=True)\n702|         PIL.Image.fromarray(im).save(fname, format=\"png\")\n703| \n704|     def set_data(self, A):\n705|         \"\"\"\n706|         Set the image array.\n707| \n708|         Note that this function does *not* update the normalization used.\n709| \n710|         Parameters\n711|         ----------\n712|         A : array-like or `PIL.Image.Image`\n713|         \"\"\"\n714|         if isinstance(A, PIL.Image.Image):\n715|             A = pil_to_array(A)  # Needed e.g. to apply png palette.\n716|         self._A = cbook.safe_masked_invalid(A, copy=True)\n717| \n718|         if (self._A.dtype != np.uint8 and\n719|                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n720|             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n721|                             \"float\".format(self._A.dtype))\n722| \n723|         if self._A.ndim == 3 and self._A.shape[-1] == 1:\n724|             # If just one dimension assume scalar and apply colormap\n725|             self._A = self._A[:, :, 0]\n726| \n727|         if not (self._A.ndim == 2\n728|                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n729|             raise TypeError(\"Invalid shape {} for image data\"\n730|                             .format(self._A.shape))\n731| \n732|         if self._A.ndim == 3:\n733|             # If the input data has values outside the valid range (after\n734|             # normalisation), we issue a warning and then clip X to the bounds\n735|             # - otherwise casting wraps extreme values, hiding outliers and\n736|             # making reliable interpretation impossible.\n737|             high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1\n738|             if self._A.min() < 0 or high < self._A.max():\n... Code Truncated ...\n\n",
  "line_level_localization": [
    {
      "filename": "lib/matplotlib/colors.py",
      "suspect_lines": [
        1467,
        1469,
        1472,
        1474,
        1477,
        1546,
        1550
      ]
    },
    {
      "filename": "lib/matplotlib/image.py",
      "suspect_lines": [
        441,
        535,
        536,
        538,
        540,
        542,
        638
      ]
    }
  ]
}